{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc3e43d-c805-4d7e-992f-e4c413d78f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install pip earthengine-api\n",
    "# !{sys.executable} -m pip install pip geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfbd47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2456da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "import ipyleaflet\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb712a31-fee9-43f1-b401-ee3c15f71e18",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af175dac-869b-4107-b193-15d2535eef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory\n",
    "out_dir = os.getcwd()\n",
    "bucket_name = 'cities-urbanshift' \n",
    "aws_s3_dir = 'https://'+bucket_name+'.s3.eu-west-3.amazonaws.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cf02ee-040f-4f21-b30a-aafb01702762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of cities\n",
    "boundary_georef = pd.read_csv(aws_s3_dir+'/data/boundaries/v_0/boundary_georef.csv')\n",
    "boundary_georef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d3d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions to calculate vegetation and water cover raster layers\n",
    "\n",
    "NDVIthreshold = 0.4 # decimal\n",
    "NDWIthreshold = 0.3 # decimal\n",
    "halfpvalue = 0.025 # half the value of the p-value threshold to be used in the significance test. \n",
    "MAX_CLOUD_PROB=30\n",
    "date_start = '2016-01-01'\n",
    "date_end = '2022-12-31'\n",
    "\n",
    "\n",
    "S2 = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "S2C = ee.ImageCollection(\"COPERNICUS/S2_CLOUD_PROBABILITY\")\n",
    "\n",
    "## get cloudmasked image collection \n",
    "\n",
    "def mask_and_count_clouds(s2wc,geom):\n",
    "    s2wc=ee.Image(s2wc)\n",
    "    geom=ee.Geometry(geom.geometry())\n",
    "    is_cloud=ee.Image(s2wc.get('cloud_mask')).gt(MAX_CLOUD_PROB).rename('is_cloud')\n",
    "    nb_cloudy_pixels=is_cloud.reduceRegion(\n",
    "        reducer=ee.Reducer.sum().unweighted(), \n",
    "        geometry=geom, \n",
    "        scale=10, \n",
    "        maxPixels=1e9\n",
    "   )\n",
    "    return s2wc.updateMask(is_cloud.eq(0)).set('nb_cloudy_pixels',nb_cloudy_pixels.getNumber('is_cloud')).divide(10000)\n",
    "\n",
    "def mask_clouds_and_rescale(im):\n",
    "    clouds=ee.Image(im.get('cloud_mask')).select('probability')\n",
    "    return im.updateMask(clouds.lt(MAX_CLOUD_PROB)).divide(10000)\n",
    "\n",
    "def get_masked_s2_collection(roi,start,end):\n",
    "    criteria=(ee.Filter.And(\n",
    "            ee.Filter.date(start,end),\n",
    "            ee.Filter.bounds(roi)\n",
    "        ))\n",
    "    s2=S2.filter(criteria).select('B2','B3','B4','B8','B11','B12')\n",
    "    s2c=S2C.filter(criteria)\n",
    "    s2_with_clouds=(ee.Join.saveFirst('cloud_mask').apply(**{\n",
    "        'primary': ee.ImageCollection(s2),\n",
    "        'secondary': ee.ImageCollection(s2c),\n",
    "        'condition': ee.Filter.equals(**{'leftField':'system:index','rightField':'system:index'}) \n",
    "        }))\n",
    "    def _mcc(im):\n",
    "        return mask_and_count_clouds(im,roi) \n",
    "    #s2_with_clouds=ee.ImageCollection(s2_with_clouds).map(_mcc)\n",
    "    #s2_with_clouds=s2_with_clouds.limit(image_limit,'nb_cloudy_pixels')\n",
    "    s2_with_clouds=ee.ImageCollection(s2_with_clouds).map(mask_clouds_and_rescale)#.limit(image_limit,'CLOUDY_PIXEL_PERCENTAGE')\n",
    "    return  ee.ImageCollection(s2_with_clouds)\n",
    "\n",
    "\n",
    "## annual image collections and images\n",
    "\n",
    "def AnnualIC(ic,year):\n",
    "    def addNDVI(image):\n",
    "        ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "        return image.addBands(ndvi)\n",
    "    def addNDWI(image):\n",
    "        ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "        return image.addBands(ndwi)\n",
    "    def addyear(image):\n",
    "        return image.set(\"year\",year)\n",
    "    # ImgColl = ic.filterDate(''+str(year)+'-01-01', ''+str(year)+'-12-31').map(addNDVI).map(addNDWI).map(addyear)\n",
    "    ImgColl = ic.filter(ee.Filter.stringStartsWith('system:index',year)).map(addNDVI).map(addNDWI).map(addyear)\n",
    "    return ImgColl\n",
    "\n",
    "def AnnualImgGreen(ic,year):\n",
    "    # greenest = ic.qualityMosaic('NDVI').select('NDVI').addBands(ee.Image(year).rename('time_start')).float()\n",
    "    greenest = ic.select('NDVI').reduce(ee.Reducer.median()).rename('NDVI').addBands(ee.Image(year).rename('time_start')).float()\n",
    "    greenestThres = greenest.updateMask(greenest.select('NDVI').gte(NDVIthreshold))\n",
    "    bluest = ic.qualityMosaic('NDWI').select('NDWI').addBands(ee.Image(year).rename('time_start')).float()\n",
    "    # bluest = ic.select('NDWI').reduce(ee.Reducer.median()).rename('NDWI').addBands(ee.Image(year).rename('time_start')).float()\n",
    "    bluestThres = bluest.updateMask(bluest.select('NDWI').gte(NDWIthreshold))\n",
    "    greenestThresnowater = greenestThres.updateMask(bluestThres.select('NDWI').unmask().Not())\n",
    "    greenestnowater = greenest.updateMask(bluestThres.select('NDWI').unmask().Not())\n",
    "    return greenestnowater\n",
    "def AnnualImgWater(ic,year):\n",
    "    # bluest = ic.qualityMosaic('NDWI').select('NDWI').addBands(ee.Image(year).rename('time_start')).float()\n",
    "    bluest = ic.select('NDWI').reduce(ee.Reducer.median()).rename('NDWI').addBands(ee.Image(year).rename('time_start')).float()\n",
    "    greenest = ic.qualityMosaic('NDVI').select('NDVI').addBands(ee.Image(year).rename('time_start')).float()\n",
    "    greenestThres = greenest.updateMask(greenest.select('NDVI').gte(NDVIthreshold))\n",
    "    bluestnowater = bluest.updateMask(greenestThres.select('NDVI').unmask().Not())\n",
    "    return bluest\n",
    "def AnnualImgWatermask(ic,year):\n",
    "    bluest = ic.qualityMosaic('NDWI').select('NDWI').addBands(ee.Image(year).rename('time_start')).float()\n",
    "    # bluest = ic.select('NDWI').reduce(ee.Reducer.median()).rename('NDWI').addBands(ee.Image(year).rename('time_start')).float()\n",
    "    bluestThres = bluest.updateMask(bluest.select('NDWI').gte(NDWIthreshold))\n",
    "    return bluestThres\n",
    "def AnnualImgGreenmask(ic,year):\n",
    "    greenest = ic.qualityMosaic('NDVI').select('NDVI').addBands(ee.Image(year).rename('time_start')).float()\n",
    "    # greenest = ic.select('NDVI').reduce(ee.Reducer.median()).rename('NDVI').addBands(ee.Image(year).rename('time_start')).float()\n",
    "    greenestThres = greenest.updateMask(greenest.select('NDVI').gte(NDVIthreshold))\n",
    "    return greenestThres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180545c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for significance test\n",
    "# https://developers.google.com/earth-engine/tutorials/community/nonparametric-trends\n",
    "# https://code.earthengine.google.com/bce3dc00c56df4246c5d32f5fcccf5c7\n",
    "#//////////////////////////////////////singificance test///////////////////////////////////////////////////////////////\n",
    "\n",
    "    \n",
    "def senum(lfx):\n",
    "    def senumwrap(Im):\n",
    "        esty=lfx.select('scale').multiply(Im.select('time_start')).add(lfx.select('offset'))\n",
    "        diff=Im.select('NDVI').subtract(esty)\n",
    "        pow=diff.multiply(diff)\n",
    "        return (pow)\n",
    "    return (senumwrap)\n",
    "    \n",
    "def sedenom(mosaicmeanx):\n",
    "    def sedenomwrap(Im):\n",
    "        diff=Im.select('time_start').subtract(mosaicmeanx.select('time_start'));\n",
    "        pow=diff.multiply(diff);\n",
    "        return (pow)\n",
    "    return (sedenomwrap)\n",
    "    \n",
    "# https://en.wikipedia.org/wiki/Error_function#Cumulative_distribution_function\n",
    "def eeCdf(t):\n",
    "    return ee.Image(0.5).multiply(ee.Image(1).add(ee.Image(t).divide(ee.Image(2).sqrt()).erf()));\n",
    "\n",
    "def invCdf(p):\n",
    "    return ee.Image(2).sqrt().multiply(ee.Image(p).multiply(2).subtract(1).erfInv());\n",
    "\n",
    "#/////green normalized Difference///////\n",
    "def significanceGreen(gtrend,glinearfit,SampleNumber): \n",
    "    \n",
    "\n",
    "\n",
    "    mosaicmean=gtrend.mean();\n",
    "    mosaicNum=gtrend.map(senum(glinearfit)).sum();\n",
    "    mosaicDenom=gtrend.map(sedenom(mosaicmean)).sum();\n",
    "    StdDev=mosaicNum.divide(mosaicDenom);\n",
    "    #Standard Error - from SampleNumber samples\n",
    "    se= StdDev.divide(SampleNumber).sqrt();\n",
    "    #Test Statistic\n",
    "    gT=glinearfit.select('scale').divide(se);\n",
    "    # Compute P-values.\n",
    "    gP = ee.Image(1).subtract(eeCdf(gT.abs()));\n",
    "    # Pixels that can have the null hypothesis (there is no trend) rejected.\n",
    "    # Specifically, if the true trend is zero, there would be less than 5%\n",
    "    # chance of randomly obtaining the observed result (that there is a trend).\n",
    "    # glf=glfLimit.updateMask(gP.lte(0.025));  \n",
    "    # Map.addLayer(glf, {'bands':['scale'],'min': -1, 'max': 1,'palette':['red','yellow','green']}, 'significant veg trends');\n",
    "    return gP\n",
    "\n",
    "    \n",
    "#/////water normalized Difference///////\n",
    "def significanceWater(wtrend,wlinearfit,SampleNumber): \n",
    "    \n",
    "    def senum(lfx):\n",
    "        def senumwrap(Im):\n",
    "            esty=lfx.select('scale').multiply(Im.select('time_start')).add(lfx.select('offset'))\n",
    "            diff=Im.select('NDWI').subtract(esty)\n",
    "            pow=diff.multiply(diff)\n",
    "            return (pow)\n",
    "        return (senumwrap)\n",
    "\n",
    "    mosaicmean=wtrend.mean();\n",
    "    mosaicNum=wtrend.map(senum(wlinearfit)).sum();\n",
    "    mosaicDenom=wtrend.map(sedenom(mosaicmean)).sum();\n",
    "    StdDev=mosaicNum.divide(mosaicDenom);\n",
    "    #Standard Error - from SampleNumber samples\n",
    "    se= StdDev.divide(SampleNumber).sqrt();\n",
    "    #Test Statistic\n",
    "    wT=wlinearfit.select('scale').divide(se);\n",
    "    # Compute P-values.\n",
    "    wP = ee.Image(1).subtract(eeCdf(wT.abs()));\n",
    "    # Pixels that can have the null hypothesis (there is no trend) rejected.\n",
    "    # Specifically, if the true trend is zero, there would be less than 5%\n",
    "    # chance of randomly obtaining the observed result (that there is a trend).\n",
    "    # wlf=wlfLimit.updateMask(wP.lte(0.025));\n",
    "    return wP\n",
    "\n",
    "# Map\n",
    "#//----------------------------------------------------------------------------------------//\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a126afe-4631-4611-bd15-2ef2c73500a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate vegetation and water trend and change maps\n",
    "def get_map_vegwaterchange(IC):\n",
    "    \n",
    "    gwic2018 = AnnualIC(IC,'2018')\n",
    "    gwic2019 = AnnualIC(IC,'2019')\n",
    "    gwic2020 = AnnualIC(IC,'2020')\n",
    "    gwic2021 = AnnualIC(IC,'2021')\n",
    "    gwic2022 = AnnualIC(IC,'2022')\n",
    "    gwic = (\n",
    "        # gwic2018.merge\n",
    "        (gwic2019).merge(gwic2020).merge(gwic2021).merge(gwic2022))\n",
    "    # print(gwic.first().getInfo())\n",
    "\n",
    "    d = {}\n",
    "    for i in range(2019,2023):\n",
    "        # https://stackoverflow.com/questions/6181935/how-do-you-create-different-variable-names-while-in-a-loop\n",
    "        filteredgwic = gwic.filter(ee.Filter.eq(\"year\",str(i)))\n",
    "        d[\"g{0}\".format(i)] = AnnualImgGreen(filteredgwic,i)\n",
    "        d[\"w{0}\".format(i)] = AnnualImgWater(filteredgwic,i)\n",
    "        d[\"w{0}mask\".format(i)] = AnnualImgWatermask(filteredgwic,i)\n",
    "        d[\"g{0}mask\".format(i)] = AnnualImgGreenmask(filteredgwic,i)\n",
    "    \n",
    "    gtrend = ee.ImageCollection.fromImages([#d[\"g2018\"],\n",
    "                                            d[\"g2019\"],d[\"g2020\"],d[\"g2021\"],d[\"g2022\"]])\n",
    "    wtrend = ee.ImageCollection.fromImages([#d[\"w2018\"],\n",
    "                                            d[\"w2019\"],d[\"w2020\"],d[\"w2021\"],d[\"w2022\"]])\n",
    "    wanyyear = (ee.Image(\n",
    "        #d[\"w2018mask\"].select('NDWI')).blend(\n",
    "        d[\"w2019mask\"].select('NDWI'))\n",
    "        .blend(d[\"w2020mask\"].select('NDWI'))\n",
    "        .blend(d[\"w2021mask\"].select('NDWI'))\n",
    "        .blend(d[\"w2022mask\"].select('NDWI'))\n",
    "                )\n",
    "    ganyyear = (ee.Image(\n",
    "        #d[\"g2018mask\"].select('NDVI')).blend(\n",
    "        d[\"g2019mask\"].select('NDVI'))\n",
    "        .blend(d[\"g2020mask\"].select('NDVI'))\n",
    "        .blend(d[\"g2021mask\"].select('NDVI'))\n",
    "        .blend(d[\"g2022mask\"].select('NDVI'))\n",
    "                )\n",
    "    startyear = ee.Number(2019)\n",
    "    endyear = ee.Number(2022)\n",
    "    sampleNumber = (endyear.subtract(startyear)).add(1)\n",
    "    gstartmask = AnnualImgGreenmask(gwic.filter(ee.Filter.eq(\"year\",'2019')),startyear)\n",
    "    wstartmask = AnnualImgWatermask(gwic.filter(ee.Filter.eq(\"year\",'2019')),startyear)\n",
    "    gendmask = AnnualImgGreenmask(gwic.filter(ee.Filter.eq(\"year\",'2022')),endyear)\n",
    "    wendmask = AnnualImgWatermask(gwic.filter(ee.Filter.eq(\"year\",'2022')),endyear)   \n",
    "    \n",
    "    minSlopeVeg = ee.Number(0.1) #0.05 #   minimum threshold scale value from linear fit trend line to be considered a vegetation change. \n",
    "    minSlopeWater = ee.Number(0.1) # 0.05 #  minimum threshold scale value from linear fit trend line to be considered a water change. \n",
    "\n",
    "    # Create linear fit trend line for years of NDVI data\n",
    "    # https://developers.google.com/earth-engine/guides/reducers_regression#linearfit\n",
    "    glinearfit = ee.Image(gtrend.select(['time_start','NDVI']).reduce(ee.Reducer.linearFit()));\n",
    "\n",
    "    ## apply significance test\n",
    "    # Pixels that can have the null hypothesis (there is no trend) rejected.\n",
    "    # Specifically, if the true trend is zero, there would be less than 5% (double \"halfpvalue\")\n",
    "    # chance of randomly obtaining the observed result (that there is a trend).\n",
    "    gsignifMask = significanceGreen(gtrend,glinearfit,sampleNumber).lte(halfpvalue)\n",
    "    glinearfit = glinearfit.updateMask(gsignifMask)\n",
    "\n",
    "    # Annual slope value for each pixel above threshold. If interested in value for timeperiod, can use .multiply(ee.Image(6)). Can also mask based on offset to limit based on starting vegetation level. \n",
    "    glfLimit = (glinearfit.select('scale')#.multiply(ee.Image(6))\n",
    "                .updateMask(glinearfit.select('scale').gte(minSlopeVeg).Or(glinearfit.select('scale').lte(ee.Number(0).subtract(minSlopeVeg))))\n",
    "                #.updateMask(glinearfit.select('offset').gte(-0.1))\n",
    "               )\n",
    "    greenanyyearMask = ee.Image(0).where(ganyyear.neq(0),1)\n",
    "    # Map.addLayer(greenanyyearMask,{},'green any year mask')\n",
    "\n",
    "    glfLimitanyyeargreen = glfLimit.updateMask(greenanyyearMask)\n",
    "    glfLimitanyyeargreenLoss = glfLimitanyyeargreen.updateMask(glfLimitanyyeargreen.lt(0))\n",
    "    glfLimitanyyeargreenGain = glfLimitanyyeargreen.updateMask(glfLimitanyyeargreen.gt(0))\n",
    "\n",
    "    # Map.addLayer(glfLimitanyyeargreen,{\"min\": -0.3, \"max\": 0.3, \"palette\":[\"red\",\"yellow\",\"green\"]},\"Veg Trend\");\n",
    "\n",
    "    # Create linear fit trend line for years of NDWI data\n",
    "    wlinearfit = ee.Image(wtrend.select(['time_start','NDWI']).reduce(ee.Reducer.linearFit()));\n",
    "    \n",
    "    ## apply significance test\n",
    "    # Pixels that can have the null hypothesis (there is no trend) rejected.\n",
    "    # Specifically, if the true trend is zero, there would be less than 5% (double \"halfpvalue\")\n",
    "    # chance of randomly obtaining the observed result (that there is a trend).\n",
    "    wsignifMask = significanceWater(wtrend,wlinearfit,sampleNumber).lte(halfpvalue)\n",
    "    wlinearfit = wlinearfit.updateMask(wsignifMask)\n",
    "    \n",
    "    # Annual slope value for each pixel above threshold. If interested in value for timeperiod, can use .multiply(ee.Image(6)). Can also mask based on offset to limit based on starting vegetation level. \n",
    "    wlfLimit = (wlinearfit.select('scale')#.multiply(ee.Image(6))\n",
    "                .updateMask(wlinearfit.select('scale').gte(minSlopeWater).Or(wlinearfit.select('scale').lte(ee.Number(0).subtract(minSlopeVeg))))\n",
    "                #.updateMask(wlinearfit.select('offset').gte(-0.1))\n",
    "               )\n",
    "\n",
    "    wateranyyearMask = ee.Image(0).where(wanyyear.neq(0),1)\n",
    "    # Map.addLayer(wateranyyearMask,{},'water any year mask')\n",
    "\n",
    "    wlfLimitanyyearwater = wlfLimit.updateMask(wateranyyearMask)\n",
    "    wlfLimitanyyearwaterLoss = wlfLimitanyyearwater.updateMask(wlfLimitanyyearwater.lt(0))\n",
    "    wlfLimitanyyearwaterGain = wlfLimitanyyearwater.updateMask(wlfLimitanyyearwater.gt(0))\n",
    "\n",
    "    # Map.addLayer(wlfLimitanyyearwater,{\"min\": -0.3, \"max\": 0.3, \"palette\":['brown','white','blue']},\"Water Trend\");\n",
    "    #Map.addLayer(wlfLimitanyyearwaterLoss,{\"min\": -0.3, \"max\": 0.3, \"palette\":['brown','white','blue']},\"Water Trend Loss\");\n",
    "    #Map.addLayer(wlfLimitanyyearwaterGain,{\"min\": -0.3, \"max\": 0.3, \"palette\":['brown','white','blue']},\"Water Trend Gain\");\n",
    "\n",
    "    gorwstartmask = gstartmask.select('NDVI').blend(wstartmask.select('NDWI'))\n",
    "    gorwendmask = gendmask.select('NDVI').blend(wendmask.select('NDWI'))\n",
    "    greenorwaterLimitLoss = glfLimitanyyeargreenLoss.blend(wlfLimitanyyearwaterLoss)\n",
    "    greenorwaterLimitGain = glfLimitanyyeargreenGain.blend(wlfLimitanyyearwaterGain)\n",
    "    combinedStartLossGain = gorwstartmask.rename('startgreenwater').addBands(gorwendmask.rename('endgreenwater')).addBands(greenorwaterLimitLoss.rename('lossgreenwater')).addBands(greenorwaterLimitGain.rename('gaingreenwater'))\n",
    "\n",
    "    return combinedStartLossGain\n",
    "    # Map.addLayer(gorw2016mask,{\"min\": -0.3, \"max\": 0.3, \"palette\":['brown','white','blue']},\"2016 green or water\");\n",
    "    # Map.addLayer(greenorwaterLimitLoss,{\"min\": -0.3, \"max\": 0.3, \"palette\":['brown','white','blue']},\"Green or water Loss\");\n",
    "    # Map.addLayer(greenorwaterLimitGain,{\"min\": -0.3, \"max\": 0.3, \"palette\":['brown','white','blue']},\"Green or water Gain\");\n",
    "\n",
    "# define calcuation function to get pixel counts, convert to percents and append to data frame\n",
    "def CountCalcs(vegwaterImg,boundary,results):   \n",
    "    \n",
    "    # reduce images to get counts by region\n",
    "    # counts = stackedForCount.reduceRegions(FC,ee.Reducer.count(),10)\n",
    "    counts = vegwaterImg.select('startgreenwater').reduceRegions(collection=boundary,reducer=ee.Reducer.count().setOutputs(['greenorwater2018']),scale=30)#,tileScale=10)\n",
    "    counts = vegwaterImg.select('lossgreenwater').reduceRegions(collection=counts,reducer=ee.Reducer.count().setOutputs(['greenorwaterLoss']),scale=30)#,tileScale=10)\n",
    "    counts = vegwaterImg.select('gaingreenwater').reduceRegions(collection=counts,reducer=ee.Reducer.count().setOutputs(['greenorwaterGain']),scale=30)#,tileScale=10)\n",
    "\n",
    "    # convert pixel counts to area percentages and saves to FC as property\n",
    "    def toPct(feat):\n",
    "\n",
    "        # convert 10m pixel count to KM2 \n",
    "        # convert10mtoKM2 = ee.Number(100).multiply(ee.Number(0.000001))\n",
    "        # FeatAreafromPixelsKM2 = feat.getNumber('pixels').multiply(convert10mtoKM2)\n",
    "\n",
    "        # vegArea2016KM2 = feat.getNumber('NDVI2016').multiply(convert10mtoKM2)\n",
    "        # waterArea2016KM2 = feat.getNumber('NDWI2016').multiply(convert10mtoKM2)\n",
    "        # vegArea2021KM2 = feat.getNumber('NDVI2021').multiply(convert10mtoKM2)\n",
    "        # waterArea2021KM2 = feat.getNumber('NDWI2021').multiply(convert10mtoKM2)\n",
    "        # vegPct2021 = ee.Number(vegArea2021KM2).divide(FeatAreafromPixelsKM2)\n",
    "        # # waterPct2021 = ee.Number(waterArea2021KM2).divide(FeatAreafromPixelsKM2)\n",
    "        # vegGainKM2 = feat.getNumber('greenGain').multiply(convert10mtoKM2)\n",
    "        # vegLossKM2 = feat.getNumber('greenLoss').multiply(convert10mtoKM2)\n",
    "        # vegNetChangeKM2 = vegGainKM2.subtract(vegLossKM2)\n",
    "        # vegNetChangePct = vegNetChangeKM2.divide(vegArea2016KM2)\n",
    "        # waterGainKM2 = feat.getNumber('waterGain').multiply(convert10mtoKM2)\n",
    "        # waterLossKM2 = feat.getNumber('waterLoss').multiply(convert10mtoKM2)\n",
    "        # waterNetChangeKM2 = waterGainKM2.subtract(waterLossKM2)\n",
    "        # waterNetChangePct = waterNetChangeKM2.divide(waterArea2016KM2)\n",
    "        # greenorwaterArea2016KM2 = feat.getNumber('greenorwater2016').multiply(convert10mtoKM2)\n",
    "        # greenorwaterGainKM2 = feat.getNumber('greenorwaterGain').multiply(convert10mtoKM2)\n",
    "        # greenorwaterLossKM2 = feat.getNumber('greenorwaterLoss').multiply(convert10mtoKM2)\n",
    "        # greenorwaterNetChangeKM2 = greenorwaterGainKM2.subtract(greenorwaterLossKM2)\n",
    "        # greenorwaterNetChangePct = greenorwaterNetChangeKM2.divide(greenorwaterArea2016KM2)\n",
    "        # vegNetChangePct = (feat.getNumber('greenGain').subtract(feat.getNumber('greenLoss'))).divide(feat.getNumber('green2016'))\n",
    "        # waterNetChangePct = (feat.getNumber('waterGain').subtract(feat.getNumber('waterLoss'))).divide(feat.getNumber('water2016'))\n",
    "        greenorwaterNetChangePct = (feat.getNumber('greenorwaterGain').subtract(feat.getNumber('greenorwaterLoss'))).divide(feat.getNumber('greenorwater2018'))\n",
    "        \n",
    "        return feat.set({\n",
    "            # 'TotalareaFromPixelsKM2': FeatAreafromPixelsKM2,\n",
    "            # 'vegArea2021KM2': vegArea2021KM2,\n",
    "            # 'waterArea2021KM2':waterArea2021KM2,\n",
    "            # 'vegPct2021':vegPct2021,\n",
    "            # 'waterPct2021':waterPct2021,\n",
    "            # 'vegGainKM2':vegGainKM2,\n",
    "            # 'vegLossKM2':vegLossKM2,\n",
    "            # 'waterGainKM2':waterGainKM2,\n",
    "            # 'waterLossKM2':waterLossKM2,\n",
    "            # 'vegChangeKM2': vegNetChangeKM2,\n",
    "            # 'vegChangePct': vegNetChangePct,\n",
    "            # 'waterChangeKM2': waterNetChangeKM2,\n",
    "            # 'waterChangePct': waterNetChangePct,\n",
    "            # 'greenorwaterChangeKM2': greenorwaterNetChangeKM2,\n",
    "            'greenorwaterChangePct': greenorwaterNetChangePct\n",
    "        })\n",
    "\n",
    "    counts = counts.map(toPct).select(['geo_id','greenorwaterChangePct'],['geo_id','LND_3_percentChangeinVegetation&WaterCover2019-2022'])\n",
    "\n",
    "    # # store in df and apend\n",
    "    df = geemap.ee_to_pandas(counts)\n",
    "    results = pd.concat([results,df])\n",
    "    # results = ee.FeatureCollection([results,counts]).flatten()\n",
    "    # results = counts  \n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a93f23a-1020-440c-a24e-530afe929371",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_indicator = pd.DataFrame() \n",
    "# this_indicator = ee.FeatureCollection([])\n",
    "# listofFC = ee.List([])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc30780c-60fd-44ab-989e-c9996bd41fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply methods to each city - CURRENTLY EXPERIENCING GEE MEMORY ERRORS FOR LARGE CITIES \n",
    "\n",
    "for i in range(29,len(boundary_georef)):\n",
    "    print(i)\n",
    "    geo_name = boundary_georef.loc[i, 'geo_name']\n",
    "    print(\"\\n geo_name: \"+geo_name)\n",
    "    \n",
    "    boundary_id_aoi = boundary_georef.loc[i, 'geo_name']+'-'+boundary_georef.loc[i, 'aoi_boundary_name']\n",
    "    boundary_id_unit = boundary_georef.loc[i, 'geo_name']+'-'+boundary_georef.loc[i, 'units_boundary_name']\n",
    "        \n",
    "    # process aoi level ------\n",
    "    print(\"\\n boundary_id_aoi: \"+boundary_id_aoi)\n",
    "    # read boundaries\n",
    "    boundary_path = aws_s3_dir +'/data/boundaries/v_0/boundary-'+boundary_id_aoi+'.geojson'\n",
    "    boundary_geo = requests.get(boundary_path).json()\n",
    "    boundary_geo_ee = geemap.geojson_to_ee(boundary_geo)\n",
    "    \n",
    "    s2cloudmasked = get_masked_s2_collection(boundary_geo_ee,date_start,date_end)\n",
    "    vegwatermap = get_map_vegwaterchange(s2cloudmasked)\n",
    "\n",
    "    this_indicator = CountCalcs(vegwatermap,boundary_geo_ee,this_indicator)\n",
    "    # listofFC = listofFC.add(this_city_indicator)\n",
    "    \n",
    "    # process unit of analysis level ------\n",
    "    print(\"\\n boundary_id_unit: \"+boundary_id_unit)\n",
    "    # read boundaries\n",
    "    boundary_path = aws_s3_dir +'/data/boundaries/v_0/boundary-'+boundary_id_unit+'.geojson'\n",
    "    boundary_geo = requests.get(boundary_path).json()\n",
    "    boundary_geo_ee = geemap.geojson_to_ee(boundary_geo)\n",
    "    this_indicator = CountCalcs(vegwatermap,boundary_geo_ee,this_indicator)\n",
    "    # listofFC = listofFC.add(this_city_indicator)\n",
    "    \n",
    "# this_indicator = ee.FeatureCollection(listofFC).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc107cb5-a1cc-4def-9210-51a7b0dcd6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geemap.ee_to_csv(this_indicator, '/this_indicator.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b0356-d2f4-4799-b05d-a530e5e21e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # ee.data.createAsset({'type': 'Folder'},'users/emackres/this_indicator',True)\n",
    "# # ee.data.deleteAsset('users/emackres/this_indicator')\n",
    "# exportTask = ee.batch.Export.table.toAsset(\n",
    "#     collection = this_indicator,\n",
    "#     description = 'description',\n",
    "#     assetId = 'users/emackres/this_indicator'\n",
    "# )\n",
    "# exportTask.start()\n",
    "\n",
    "# exportTask = ee.batch.Export.table.toDrive(\n",
    "#     collection = this_indicator,\n",
    "#     description = 'this_indicator',\n",
    "#     folder='data',\n",
    "#     selectors=([\"geo_id\",\"LND_3_percentChangeinVegetation&WaterCover2019-2022\"]),\n",
    "#     fileFormat='CSV'\n",
    "# )\n",
    "# exportTask.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd697c4d-9e84-4b2e-a31b-bd77c648783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportTask.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598c6b39-d49e-4269-8b05-1afe9f79f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_indicator = ee.FeatureCollection('users/emackres/this_indicator')\n",
    "# this_indicator = geemap.ee_to_pandas(this_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32918c31-4140-429d-b7aa-10e636d948d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_indicator  #.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f73aa8d-90b8-45ee-b120-3a5f253e21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create map\n",
    "Map = geemap.Map(height=\"400px\")\n",
    "## add basemap and center on area of interest\n",
    "Map.add_basemap('HYBRID')\n",
    "# Map.centerObject(boundary_geo_ee,11)\n",
    "vegwaterstartmap = vegwatermap.select('startgreenwater')\n",
    "vegwaterendmap = vegwatermap.select('endgreenwater')\n",
    "vegwaterchangemap = vegwatermap.select('lossgreenwater').blend(vegwatermap.select('gaingreenwater'))\n",
    "Map.addLayer(vegwaterstartmap,{'palette':['white','green'],'min':0,'max':1},'vegetation or water in start year')\n",
    "Map.addLayer(vegwaterendmap,{'palette':['white','green'],'min':0,'max':1},'vegetation or water in end year')\n",
    "Map.addLayer(vegwaterchangemap,{'palette':['#c75d9d','#96bc3e'],'min':-0.15,'max':0.15},'vegetation or water change')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc7dad-8479-426b-9a26-76ae9910e965",
   "metadata": {},
   "source": [
    "# Merge with indicator table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731fba45-59b3-44fe-94a9-3520763dffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read indicator table \n",
    "cities_indicators = pd.read_csv(aws_s3_dir + '/indicators/urbanshift_indicators_v4.csv') \n",
    "cities_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978df631-317b-4c42-8c8a-d8ee108e1715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_indicators(indicator_table, new_indicator_table, indicator_name):\n",
    "    if indicator_name in indicator_table.columns:\n",
    "        print(\"replace with new calculations\")\n",
    "        indicator_table.drop(indicator_name, inplace=True, axis=1)\n",
    "        new_indicator_table = new_indicator_table.drop_duplicates()\n",
    "        cities_indicators_df = indicator_table.merge(new_indicator_table[[\"geo_id\",indicator_name]], \n",
    "                                                     on='geo_id', \n",
    "                                                     how='left',\n",
    "                                                     validate='one_to_many')\n",
    "    else:\n",
    "        print(\"add new indicators\")\n",
    "        new_indicator_table = new_indicator_table.drop_duplicates()\n",
    "        cities_indicators_df = indicator_table.merge(new_indicator_table[[\"geo_id\",indicator_name]], \n",
    "                                                     on='geo_id', \n",
    "                                                     how='left',\n",
    "                                                     validate='one_to_many')\n",
    "    return(cities_indicators_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47025947-7f5b-4e85-91ca-91e09aedb0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cities_indicators_merged = merge_indicators(indicator_table = cities_indicators,\n",
    "                                            new_indicator_table = this_indicator,\n",
    "                                            indicator_name = 'LND_3_percentChangeinVegetation&WaterCover2019-2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c10c1e2-9aa9-4d43-a110-8550e4f36e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cities_indicators_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb0f93e-f436-4093-a3f2-14ce1cddef53",
   "metadata": {},
   "source": [
    "# Upload in aws s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c059a57-b6a6-4354-b24b-f45102ec8399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# connect to s3\n",
    "aws_credentials = pd.read_csv('/home/jovyan/PlanetaryComputerExamples/aws_credentials.csv')\n",
    "# aws_credentials = pd.read_csv('C:\\\\Users\\\\Saif.Shabou\\\\OneDrive - World Resources Institute\\\\Documents\\\\aws\\\\credentials.csv')\n",
    "aws_key = aws_credentials.iloc[0]['Access key ID']\n",
    "aws_secret = aws_credentials.iloc[0]['Secret access key']\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    aws_access_key_id=aws_key,\n",
    "    aws_secret_access_key=aws_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2235f8-fb77-40f6-91d8-908dca3fd164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to aws\n",
    "key_data = 'indicators/cities_indicators_ericV1.csv'\n",
    "\n",
    "cities_indicators_merged.to_csv(\n",
    "    f\"s3://{bucket_name}/{key_data}\",\n",
    "    index=False,\n",
    "    storage_options={\n",
    "        \"key\": aws_key,\n",
    "        \"secret\": aws_secret\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ed391-015d-4778-acc5-37c0c7a04703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make it public\n",
    "object_acl = s3.ObjectAcl(bucket_name,key_data)\n",
    "response = object_acl.put(ACL='public-read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae26d53d-d0fe-408d-a81c-047466a4f231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3084c2e-0dff-4e00-b19e-2ca5143f0bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db64d72-6272-4a93-b6e0-8f2e50f870a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df3bc15-a933-4174-b875-c5c1c8a50a11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
