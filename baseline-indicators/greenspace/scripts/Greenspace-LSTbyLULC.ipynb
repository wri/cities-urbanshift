{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68546f99-1220-49dc-9ae3-4b95426b5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installations to run in Planetary Computer environment - uncomment for first time running in environment\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install pip earthengine-api\n",
    "#!{sys.executable} -m pip install pip geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfbd47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "#ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2456da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "import ipyleaflet\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc7554",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify areas of interest / districts and metadata\n",
    "## URL method accessed an UrbanShift city's boundaries and uses information from file name and geoBoundaries properties (\"geo_name\") to create properties for output file\n",
    "URL = 'https://cities-urbanshift.s3.eu-west-3.amazonaws.com/data/boundaries/v_0/boundary-CRI-San_Jose-ADM2.geojson'\n",
    "#'https://cities-urbanshift.s3.eu-west-3.amazonaws.com/data/boundaries/ADM1/boundary-MAR-Marrakech-ADM1.geojson'\n",
    "DistrictsGJ = requests.get(URL).json()\n",
    "Districts = geemap.geojson_to_ee(DistrictsGJ)\n",
    "\n",
    "#URL = 'https://cities-urbanshift.s3.eu-west-3.amazonaws.com/data/boundaries/urban_edge_t3.geojson'\n",
    "#DistrictsGDF = gpd.read_file(URL)\n",
    "#DistrictsGDF.sample(3)\n",
    "#Districts = geemap.gdf_to_ee(DistrictsGDF)\n",
    "\n",
    "#Districts = ee.FeatureCollection('users/emackres/Wards/Addis_Ababa_Woredas')\n",
    "#Districts = ee.FeatureCollection('projects/wri-datalab/AUE/urban_edge/urban_edge_t3').first()\n",
    "\n",
    "cityname = os.path.splitext(os.path.basename(URL))[0].split('-',2)[2].rsplit('-',1)[0]\n",
    "def Rename(feat):\n",
    "    return feat.set('geo_name',cityname)\n",
    "#Districts = Districts.union(1).map(Rename)\n",
    "\n",
    "DistrictsProjCRS = Districts.geometry().projection().crs()\n",
    "print(DistrictsProjCRS.getInfo())\n",
    "print(Districts.first().getString('geo_name').getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb7d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract area properties from standarized filename\n",
    "# https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
    "basename = os.path.splitext(os.path.basename(URL))[0]\n",
    "AOIname = basename.split('-',1)[1].rsplit('-',1)[0]\n",
    "\n",
    "Areaofinterest = AOIname ## 3-letter country abreviation - city name with underscore for spaces, e.g. \"ETH-Addis_Ababa\"\n",
    "print(Areaofinterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30483f62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## create map\n",
    "Map = geemap.Map(height=\"350px\")\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69433526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## add basemap and center on area of interest\n",
    "Map.add_basemap('HYBRID')\n",
    "Map.centerObject(Districts, zoom=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add Land use land cover dataset\n",
    "WC = ee.ImageCollection(\"ESA/WorldCover/v100\")\n",
    "WorldCover = WC.first();\n",
    "\n",
    "## define projection for use later\n",
    "WCprojection = WC.first().projection();  \n",
    "print('WorldCover projection:', WCprojection.getInfo());\n",
    "\n",
    "Map.addLayer(WorldCover, {'bands': \"Map\"}, \"WorldCover 10m 2020 (ESA)\",1);\n",
    "\n",
    "Map.add_legend(builtin_legend='ESA_WorldCover',position='bottomleft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b055b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add intra-urban land use dataset\n",
    "\n",
    "ULU = ee.ImageCollection(\"projects/wri-datalab/urban_land_use/v1\")\n",
    "\n",
    "WRIulu = ULU.select('lulc').reduce(ee.Reducer.firstNonNull()).rename('lulc')\n",
    "WRIulu = WRIulu.mask(WRIulu.mask().gt(0))\n",
    "WRIroad = ULU.select('road_lulc').reduce(ee.Reducer.firstNonNull()).rename('lulc')\n",
    "WRIuluwRoad = WRIulu.add(WRIroad).where(WRIroad.eq(1),6).mask(WRIulu.mask().gt(0))\n",
    "\n",
    "ULUmaskedESA = WRIuluwRoad.updateMask(WorldCover.eq(50)) #.Or(WorldCover.eq(60)))\n",
    "\n",
    "ULUmaskedESA = ULUmaskedESA.reproject(\n",
    "      crs= WCprojection\n",
    "    )\n",
    "\n",
    "CLASSES_7=[\n",
    "  \"open_space\",\n",
    "  \"nonresidential\",\n",
    "  \"atomistic\",\n",
    "  \"informal_subdivision\",\n",
    "  \"formal_subdivision\",\n",
    "  \"housing_project\",\n",
    "  \"road\"]\n",
    "COLORS_7=[\n",
    "  '33A02C',\n",
    "  'E31A1C',\n",
    "  'FB9A99',\n",
    "  'FFFF99',\n",
    "  '1F78B4',\n",
    "  'A6CEE3',\n",
    "  '3f3f3f']  \n",
    "ULU7Params = {\"bands\": ['lulc'], 'min': 0, 'max': 6, \"opacity\": 1, \"palette\": COLORS_7}\n",
    "\n",
    "#Map.addLayer(ULUmaskedESA,ULU7Params,\"Urban Land Use 2020 (WRI) masked to WorldCover built\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c000d24-9728-40bf-be74-1a36d7f85dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set geometries and date range of interest for land surface temperature (LST) calculation\n",
    "\n",
    "roi = Districts\n",
    "ROIcenter = roi.geometry().centroid(1)\n",
    "\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2022-06-28'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11852efa-64fe-43e3-ab1f-95b8e7b692b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  CALCULATE DATES OF HOTTEST PERIOD OF HIGH TEMPERATURES FOR EACH PIXEL\n",
    "\n",
    "# select dataset, filter by dates and visualize\n",
    "dataset = (ee.ImageCollection('NASA/NEX-GDDP')\n",
    "           .filter(ee.Filter.And(\n",
    "               ee.Filter.date(start_date, end_date),\n",
    "               ee.Filter.eq('scenario','rcp85'),\n",
    "                ee.Filter.eq('model','BNU-ESM'),\n",
    "               ee.Filter.bounds(Districts)\n",
    "           ))\n",
    "          )\n",
    "AirTemperature = dataset.select(['tasmax'])\n",
    "AirTemperatureVis = {\n",
    "  'min': 240.0,\n",
    "  'max': 300.0,\n",
    "  'palette': ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'],\n",
    "}\n",
    "\n",
    "#Map.addLayer(AirTemperature, AirTemperatureVis, 'Max Air Temperature')\n",
    "#print(AirTemperature)\n",
    "\n",
    "# add date as a band to image collection\n",
    "def addDate(image):\n",
    "    img_date = ee.Date(image.date())\n",
    "    img_date = ee.Number.parse(img_date.format('YYYYMMdd'))\n",
    "    return image.addBands(ee.Image(img_date).rename('date').toInt())\n",
    "\n",
    "withdates = AirTemperature.map(addDate)\n",
    "#print(withdates)\n",
    "\n",
    "# create a composite with the hottest day value and dates for every location and add to map\n",
    "hottest = withdates.qualityMosaic('tasmax')\n",
    "#print(hottest)\n",
    "#Map.addLayer(hottest.select('tasmax'), AirTemperatureVis, 'Max temp',0)\n",
    "\n",
    "# reduce composite to get the hottest date for centroid of ROI\n",
    "resolution = dataset.first().projection().nominalScale()\n",
    "NEXtempMax = ee.Number(hottest.reduceRegion(ee.Reducer.firstNonNull(), ROIcenter, resolution).get('date'))\n",
    "#print(NEXtempMax.getInfo())\n",
    "\n",
    "# convert date number to date type\n",
    "date = ee.Date.parse('YYYYMMdd',str(NEXtempMax.getInfo()))\n",
    "#print(date.getInfo())\n",
    "\n",
    "# calculate 45 days before and after hottest date.  Format as short date.\n",
    "start90days = date.advance(-44, 'day').format('YYYY-MM-dd')\n",
    "end90days = date.advance(45, 'day').format('YYYY-MM-dd')\n",
    "print(start90days.getInfo())\n",
    "print(end90days.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284eca86-3365-40ac-a1f3-b54a4f297ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select parameters: date range, and landsat satellite\n",
    "\n",
    "landsat = 'L8' # options: 'L4', 'L5', 'L7', 'L8'\n",
    "date_start = start90days # or custom date in format '2020-12-20'\n",
    "date_end = end90days # or custom date in format '2020-12-20'\n",
    "image_limit = 100\n",
    "month_start = 1\n",
    "month_end = 12\n",
    "use_ndvi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c05432-c046-4849-852e-9e316329e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CALCULATE MEAN LST MOSAIC FOR HOTTEST PERIOD USING LANDSAT\n",
    "\n",
    "\"\"\"\"\n",
    "Derived from\n",
    "LSTfun = require('users/sofiaermida/landsat_smw_lst:modules/SMWalgorithm.js')\n",
    "'Author': Sofia Ermida (sofia.ermida@ipma.pt; @ermida_sofia)\n",
    "\n",
    "This code is free and open.\n",
    "By using this code and any data derived with it,\n",
    "you agree to cite the following reference\n",
    "'in any publications derived from them':\n",
    "Ermida, S.L., Soares, P., Mantas, V., GÃ¶ttsche, F.-M., Trigo, I.F., 2020.\n",
    "    Google Earth Engine open-source code for Land Surface Temperature estimation from the Landsat series.\n",
    "    'Remote Sensing, 12 (9), 1471; https':#doi.Org/10.3390/rs12091471\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#LandsatLST = require('users/emackres/DataPortal:/Landsat_LST.js')\n",
    "#cloudmask = require('users/emackres/DataPortal:/cloudmask.js')\n",
    "\n",
    "COLLECTION = ee.Dictionary({\n",
    "  'L4': {\n",
    "    'TOA': ee.ImageCollection('LANDSAT/LT04/C01/T1_TOA'),\n",
    "    'SR': ee.ImageCollection('LANDSAT/LT04/C01/T1_SR'),\n",
    "    'TIR': ['B6',]\n",
    "  },\n",
    "  'L5': {\n",
    "    'TOA': ee.ImageCollection('LANDSAT/LT05/C01/T1_TOA'),\n",
    "    'SR': ee.ImageCollection('LANDSAT/LT05/C01/T1_SR'),\n",
    "    'TIR': ['B6',]\n",
    "  },\n",
    "  'L7': {\n",
    "    'TOA': ee.ImageCollection('LANDSAT/LE07/C01/T1_TOA'),\n",
    "    'SR': ee.ImageCollection('LANDSAT/LE07/C01/T1_SR'),\n",
    "    'TIR': ['B6_VCID_1','B6_VCID_2'],\n",
    "  },\n",
    "  'L8': {\n",
    "    'TOA': ee.ImageCollection('LANDSAT/LC08/C01/T1_TOA'),\n",
    "    'SR': ee.ImageCollection('LANDSAT/LC08/C01/T1_SR'),\n",
    "    'TIR': ['B10','B11']\n",
    "  }\n",
    "})\n",
    "\n",
    "def NDVIaddBand(landsat):\n",
    "  def wrap(image):\n",
    "\n",
    "    # choose bands\n",
    "    nir = ee.String(ee.Algorithms.If(landsat == 'L8','B5','B4'))\n",
    "    red = ee.String(ee.Algorithms.If(landsat == 'L8','B4','B3'))\n",
    "\n",
    "    # compute NDVI\n",
    "    return image.addBands(image.expression('(nir-red)/(nir+red)',{\n",
    "      'nir':image.select(nir).multiply(0.0001),\n",
    "      'red':image.select(red).multiply(0.0001)\n",
    "    }).rename('NDVI'))\n",
    "\n",
    "  return wrap\n",
    "\n",
    "\n",
    "def FVCaddBand(landsat):\n",
    "  def wrap(image):\n",
    "\n",
    "    ndvi = image.select('NDVI')\n",
    "\n",
    "    # Compute FVC\n",
    "    fvc = image.expression('((ndvi-ndvi_bg)/(ndvi_vg - ndvi_bg))**2',\n",
    "      {'ndvi':ndvi,'ndvi_bg':0.2,'ndvi_vg':0.86})\n",
    "    fvc = fvc.where(fvc.lt(0.0),0.0)\n",
    "    fvc = fvc.where(fvc.gt(1.0),1.0)\n",
    "\n",
    "    return image.addBands(fvc.rename('FVC'))\n",
    "\n",
    "  return wrap\n",
    "\n",
    "\n",
    "def NCEP_TPWaddBand(image):\n",
    "\n",
    "  # first select the day of interest\n",
    "  date = ee.Date(image.get('system:time_start'))\n",
    "  year = ee.Number.parse(date.format('yyyy'))\n",
    "  month = ee.Number.parse(date.format('MM'))\n",
    "  day = ee.Number.parse(date.format('dd'))\n",
    "  date1 = ee.Date.fromYMD(year,month,day)\n",
    "  date2 = date1.advance(1,'days')\n",
    "\n",
    "  # function compute the time difference from landsat image\n",
    "  def datedist(image):\n",
    "    return image.set('DateDist',\n",
    "      ee.Number(image.get('system:time_start')) \\\n",
    "      .subtract(date.millis()).abs())\n",
    "  \n",
    "\n",
    "  # load atmospheric data collection\n",
    "  TPWcollection = ee.ImageCollection('NCEP_RE/surface_wv') \\\n",
    "                  .filter(ee.Filter.date(date1.format('yyyy-MM-dd'), date2.format('yyyy-MM-dd'))) \\\n",
    "                  .map(datedist)\n",
    "\n",
    "  # select the two closest model times\n",
    "  closest = (TPWcollection.sort('DateDist')).toList(2)\n",
    "\n",
    "  # check if there is atmospheric data in the wanted day\n",
    "  # if not creates a TPW image with non-realistic values\n",
    "  # these are then masked in the SMWalgorithm function (prevents errors)\n",
    "  tpw1 = ee.Image(ee.Algorithms.If(closest.size().eq(0), ee.Image.constant(-999.0),\n",
    "                      ee.Image(closest.get(0)).select('pr_wtr') ))\n",
    "  tpw2 = ee.Image(ee.Algorithms.If(closest.size().eq(0), ee.Image.constant(-999.0),\n",
    "                        ee.Algorithms.If(closest.size().eq(1), tpw1,\n",
    "                        ee.Image(closest.get(1)).select('pr_wtr') )))\n",
    "\n",
    "  time1 = ee.Number(ee.Algorithms.If(closest.size().eq(0), 1.0,\n",
    "                        ee.Number(tpw1.get('DateDist')).divide(ee.Number(21600000)) ))\n",
    "  time2 = ee.Number(ee.Algorithms.If(closest.size().lt(2), 0.0,\n",
    "                        ee.Number(tpw2.get('DateDist')).divide(ee.Number(21600000)) ))\n",
    "\n",
    "  tpw = tpw1.expression('tpw1*time2+tpw2*time1',\n",
    "                            {'tpw1':tpw1,\n",
    "                            'time1':time1,\n",
    "                            'tpw2':tpw2,\n",
    "                            'time2':time2\n",
    "                            }).clip(image.geometry())\n",
    "\n",
    "  # SMW coefficients are binned by TPW values\n",
    "  # find the bin of each TPW value\n",
    "  pos = tpw.expression(\n",
    "    \"value = (TPW>0 && TPW<=6) ? 0\" + \\\n",
    "    \": (TPW>6 && TPW<=12) ? 1\" + \\\n",
    "    \": (TPW>12 && TPW<=18) ? 2\" + \\\n",
    "    \": (TPW>18 && TPW<=24) ? 3\" + \\\n",
    "    \": (TPW>24 && TPW<=30) ? 4\" + \\\n",
    "    \": (TPW>30 && TPW<=36) ? 5\" + \\\n",
    "    \": (TPW>36 && TPW<=42) ? 6\" + \\\n",
    "    \": (TPW>42 && TPW<=48) ? 7\" + \\\n",
    "    \": (TPW>48 && TPW<=54) ? 8\" + \\\n",
    "    \": (TPW>54) ? 9\" + \\\n",
    "    \": 0\",{'TPW': tpw}) \\\n",
    "    .clip(image.geometry())\n",
    "\n",
    "  # add tpw to image as a band\n",
    "  withTPW = (image.addBands(tpw.rename('TPW'),['TPW'])).addBands(pos.rename('TPWpos'),['TPWpos'])\n",
    "\n",
    "  return withTPW\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get ASTER emissivity\n",
    "aster = ee.Image(\"NASA/ASTER_GED/AG100_003\")\n",
    "\n",
    "#get ASTER FVC from NDVI\n",
    "aster_ndvi = aster.select('ndvi').multiply(0.01)\n",
    "\n",
    "aster_fvc = aster_ndvi.expression('((ndvi-ndvi_bg)/(ndvi_vg - ndvi_bg))**2',\n",
    "  {'ndvi':aster_ndvi,'ndvi_bg':0.2,'ndvi_vg':0.86})\n",
    "aster_fvc = aster_fvc.where(aster_fvc.lt(0.0),0.0)\n",
    "aster_fvc = aster_fvc.where(aster_fvc.gt(1.0),1.0)\n",
    "\n",
    "# bare ground emissivity functions for each band\n",
    "def ASTERGEDemiss_bare_band10(image):\n",
    "  return image.expression('(EM - 0.99*fvc)/(1.0-fvc)',{\n",
    "    'EM':aster.select('emissivity_band10').multiply(0.001),\n",
    "    'fvc':aster_fvc}) \\\n",
    "    .clip(image.geometry())\n",
    "\n",
    "\n",
    "def ASTERGEDemiss_bare_band11(image):\n",
    "  return image.expression('(EM - 0.99*fvc)/(1.0-fvc)',{\n",
    "    'EM':aster.select('emissivity_band11').multiply(0.001),\n",
    "    'fvc':aster_fvc}) \\\n",
    "    .clip(image.geometry())\n",
    "\n",
    "\n",
    "def ASTERGEDemiss_bare_band12(image):\n",
    "  return image.expression('(EM - 0.99*fvc)/(1.0-fvc)',{\n",
    "    'EM':aster.select('emissivity_band12').multiply(0.001),\n",
    "    'fvc':aster_fvc}) \\\n",
    "    .clip(image.geometry())\n",
    "\n",
    "\n",
    "def ASTERGEDemiss_bare_band13(image):\n",
    "  return image.expression('(EM - 0.99*fvc)/(1.0-fvc)',{\n",
    "    'EM':aster.select('emissivity_band13').multiply(0.001),\n",
    "    'fvc':aster_fvc}) \\\n",
    "    .clip(image.geometry())\n",
    "\n",
    "\n",
    "def ASTERGEDemiss_bare_band14(image):\n",
    "  return image.expression('(EM - 0.99*fvc)/(1.0-fvc)',{\n",
    "    'EM':aster.select('emissivity_band14').multiply(0.001),\n",
    "    'fvc':aster_fvc}) \\\n",
    "    .clip(image.geometry())\n",
    "\n",
    "\n",
    "def EMaddBand(landsat, use_ndvi):\n",
    "  def wrap(image):\n",
    "\n",
    "    c13 = ee.Number(ee.Algorithms.If(landsat == 'L4',0.3222,\n",
    "                            ee.Algorithms.If(landsat == 'L5',-0.0723,\n",
    "                            ee.Algorithms.If(landsat == 'L7',0.2147,\n",
    "                            0.6820))))\n",
    "    c14 = ee.Number(ee.Algorithms.If(landsat == 'L4',0.6498,\n",
    "                            ee.Algorithms.If(landsat == 'L5',1.0521,\n",
    "                            ee.Algorithms.If(landsat == 'L7',0.7789,\n",
    "                            0.2578))))\n",
    "    c = ee.Number(ee.Algorithms.If(landsat == 'L4',0.0272,\n",
    "                            ee.Algorithms.If(landsat == 'L5',0.0195,\n",
    "                            ee.Algorithms.If(landsat == 'L7',0.0059,\n",
    "                            0.0584))))\n",
    "\n",
    "    # get ASTER emissivity\n",
    "    # convolve to Landsat band\n",
    "    emiss_bare = image.expression('c13*EM13 + c14*EM14 + c',{\n",
    "      'EM13':ASTERGEDemiss_bare_band13(image),\n",
    "      'EM14':ASTERGEDemiss_bare_band14(image),\n",
    "      'c13':ee.Image(c13),\n",
    "      'c14':ee.Image(c14),\n",
    "      'c':ee.Image(c)\n",
    "      })\n",
    "\n",
    "    # compute the dynamic emissivity for Landsat\n",
    "    EMd = image.expression('fvc*0.99+(1-fvc)*em_bare',\n",
    "      {'fvc':image.select('FVC'),'em_bare':emiss_bare})\n",
    "\n",
    "    # compute emissivity directly from ASTER\n",
    "    # without vegetation correction\n",
    "    # get ASTER emissivity\n",
    "    aster = ee.Image(\"NASA/ASTER_GED/AG100_003\") \\\n",
    "      .clip(image.geometry())\n",
    "    EM0 = image.expression('c13*EM13 + c14*EM14 + c',{\n",
    "      'EM13':aster.select('emissivity_band13').multiply(0.001),\n",
    "      'EM14':aster.select('emissivity_band14').multiply(0.001),\n",
    "      'c13':ee.Image(c13),\n",
    "      'c14':ee.Image(c14),\n",
    "      'c':ee.Image(c)\n",
    "      })\n",
    "\n",
    "    # select which emissivity to output based on user selection\n",
    "    EM = ee.Image(ee.Algorithms.If(use_ndvi,EMd,EM0))\n",
    "\n",
    "    return image.addBands(EM.rename('EM'))\n",
    "\n",
    "  return wrap\n",
    "\n",
    "\n",
    "def get_lookup_table(fc, prop_1, prop_2):\n",
    "  reducer = ee.Reducer.toList().repeat(2)\n",
    "  lookup = fc.reduceColumns(reducer, [prop_1, prop_2])\n",
    "  return ee.List(lookup.get('list'))\n",
    "\n",
    "\n",
    "def LSTaddBand(landsat):\n",
    "\n",
    "  def wrap(image):\n",
    "\n",
    "    # coefficients for the Statistical Mono-Window Algorithm\n",
    "    coeff_SMW_L8 = ee.FeatureCollection([\n",
    "    ee.Feature(None, {'TPWpos': 0, 'A': 0.9751, 'B': -205.8929, 'C': 212.7173}),\n",
    "    ee.Feature(None, {'TPWpos': 1, 'A': 1.0090, 'B': -232.2750, 'C': 230.5698}),\n",
    "    ee.Feature(None, {'TPWpos': 2, 'A': 1.0541, 'B': -253.1943, 'C': 238.9548}),\n",
    "    ee.Feature(None, {'TPWpos': 3, 'A': 1.1282, 'B': -279.4212, 'C': 244.0772}),\n",
    "    ee.Feature(None, {'TPWpos': 4, 'A': 1.1987, 'B': -307.4497, 'C': 251.8341}),\n",
    "    ee.Feature(None, {'TPWpos': 5, 'A': 1.3205, 'B': -348.0228, 'C': 257.2740}),\n",
    "    ee.Feature(None, {'TPWpos': 6, 'A': 1.4540, 'B': -393.1718, 'C': 263.5599}),\n",
    "    ee.Feature(None, {'TPWpos': 7, 'A': 1.6350, 'B': -451.0790, 'C': 268.9405}),\n",
    "    ee.Feature(None, {'TPWpos': 8, 'A': 1.5468, 'B': -429.5095, 'C': 275.0895}),\n",
    "    ee.Feature(None, {'TPWpos': 9, 'A': 1.9403, 'B': -547.2681, 'C': 277.9953})\n",
    "    ])\n",
    "\n",
    "    # Select algorithm coefficients\n",
    "    coeff_SMW = ee.FeatureCollection(coeff_SMW_L8)\n",
    "\n",
    "    # Create lookups for the algorithm coefficients\n",
    "    A_lookup = get_lookup_table(coeff_SMW, 'TPWpos', 'A')\n",
    "    B_lookup = get_lookup_table(coeff_SMW, 'TPWpos', 'B')\n",
    "    C_lookup = get_lookup_table(coeff_SMW, 'TPWpos', 'C')\n",
    "\n",
    "    # Map coefficients to the image using the TPW bin position\n",
    "    A_img = image.remap(A_lookup.get(0), A_lookup.get(1),0.0,'TPWpos').resample('bilinear')\n",
    "    B_img = image.remap(B_lookup.get(0), B_lookup.get(1),0.0,'TPWpos').resample('bilinear')\n",
    "    C_img = image.remap(C_lookup.get(0), C_lookup.get(1),0.0,'TPWpos').resample('bilinear')\n",
    "\n",
    "    # select TIR band\n",
    "    tir = ee.String(ee.Algorithms.If(landsat == 'L8','B10',\n",
    "                        ee.Algorithms.If(landsat == 'L7','B6_VCID_1',\n",
    "                        'B6')))\n",
    "    # compute the LST\n",
    "    lst = image.expression(\n",
    "      'A*Tb1/em1 + B/em1 + C',\n",
    "         {'A': A_img,\n",
    "          'B': B_img,\n",
    "          'C': C_img,\n",
    "          'em1': image.select('EM'),\n",
    "          'Tb1': image.select(tir)\n",
    "         }).updateMask(image.select('TPW').lt(0).Not())\n",
    "\n",
    "\n",
    "    return image.addBands(lst.rename('LST'))\n",
    "  \n",
    "  return wrap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cloudmask for TOA data\n",
    "def cloudmasktoa(image):\n",
    "  qa = image.select('BQA')\n",
    "  mask = qa.bitwiseAnd(1 << 4).eq(0)\n",
    "  return image.updateMask(mask)\n",
    "\n",
    "\n",
    "# cloudmask for SR data\n",
    "def cloudmasksr(image):\n",
    "  qa = image.select('pixel_qa')\n",
    "  mask = qa.bitwiseAnd(1 << 3) \\\n",
    "    .Or(qa.bitwiseAnd(1 << 5))\n",
    "  return image.updateMask(mask.Not())\n",
    "\n",
    "\n",
    "def LSTcollection(landsat, date_start, date_end, geometry, image_limit, use_ndvi):\n",
    "\n",
    "  # load TOA Radiance/Reflectance\n",
    "  collection_dict = ee.Dictionary(COLLECTION.get(landsat))\n",
    "\n",
    "  landsatTOA = ee.ImageCollection(collection_dict.get('TOA')) \\\n",
    "                .filter(ee.Filter.date(date_start, date_end)) \\\n",
    "                .filterBounds(geometry) \\\n",
    "                .map(cloudmasktoa)\n",
    "                #.limit(image_limit,'CLOUD_COVER_LAND') \\\n",
    "    \n",
    "  # load Surface Reflectance collection for NDVI\n",
    "  landsatSR = ee.ImageCollection(collection_dict.get('SR')) \\\n",
    "                .filter(ee.Filter.date(date_start, date_end)) \\\n",
    "                .filterBounds(geometry) \\\n",
    "                .map(cloudmasksr) \\\n",
    "                .map(NDVIaddBand(landsat)) \\\n",
    "                .map(FVCaddBand(landsat)) \\\n",
    "                .map(NCEP_TPWaddBand) \\\n",
    "                .map(EMaddBand(landsat,use_ndvi))\n",
    "                #.limit(image_limit,'CLOUD_COVER_LAND') \\\n",
    "\n",
    "# combine collections\n",
    "# all channels from surface reflectance collection\n",
    "# except tir channels: from TOA collection\n",
    "# select TIR bands\n",
    "  tir = ee.List(collection_dict.get('TIR'))\n",
    "  landsatALL = (landsatSR.combine(landsatTOA.select(tir), True))\n",
    "\n",
    "  # compute the LST\n",
    "  landsatLST = landsatALL.map(LSTaddBand(landsat))\n",
    "\n",
    "  return landsatLST\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05526cf3-ccdd-4abc-b8b6-276d2a4bc3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get landsat collection with added variables: NDVI, FVC, TPW, EM, LST\n",
    "# link to the code that computes the Landsat LST\n",
    "\n",
    "#LandsatColl = LandsatLST.collection(landsat, date_start, date_end, roi, use_ndvi)\n",
    "\n",
    "LandsatColl = LSTcollection(landsat, date_start, date_end, roi, image_limit, use_ndvi).filter(ee.Filter.calendarRange(month_start, month_end, 'month'))\n",
    "\n",
    "LSTmean = LandsatColl.select('LST').reduce(ee.Reducer.mean()).subtract(273.15)\n",
    "#print(LSTmean)\n",
    "\n",
    "# define \"high LST\" threshold\n",
    "UrbanLSTmean = LSTmean.mask(WorldCover.eq(50))\n",
    "UrbanAreaLSTReduction = UrbanLSTmean.reduceRegion(ee.Reducer.mean(),roi,30) # or ee.Reducer.percentile([50]) for median LST of region\n",
    "thesholdAdder = 3 # degrees C above UrbanAreaReduction value at which to set threshold\n",
    "TempThresValue = ee.Number(UrbanAreaLSTReduction.get('LST_mean')).multiply(100).round().divide(100).add(thesholdAdder).getInfo()\n",
    "print(TempThresValue)\n",
    "\n",
    "LSTmeanThres = LSTmean.updateMask(LSTmean.gte(TempThresValue))\n",
    "\n",
    "#print(LSTmean.getInfo())\n",
    "#print(LSTmean.projection().nominalScale().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de62ca-5b47-4125-9b54-23558bdfd9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add LST mean to map\n",
    "\n",
    "cmap1 = ['blue', 'cyan', 'green', 'yellow', 'red']\n",
    "Map.addLayer(LSTmean,{'min':20, 'max':45, 'palette':cmap1}, 'Mean land surface temperature C',False)\n",
    "Map.addLayer(LSTmeanThres,{'min':20, 'max':45, 'palette':cmap1}, 'Mean land surface temperature C, areas '+str(thesholdAdder)+'C+ above built-up mean',True)\n",
    "\n",
    "Map.addLayer(roi,{}, \"Area of interest\",True,0.3)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2679421",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculations to determine LST by LULC class\n",
    "\n",
    "\n",
    "## function to create image of means of toCount for each asClass\n",
    "\n",
    "def getmeanbyclass(classvalue):\n",
    "    return ee.Image(toCount.updateMask(asClass.eq(classvalue)) #.And(toCount.gt(0))) # uncomment And statement if you want include only pixels that meet both criteria\n",
    "                    # .unmask(0) # uncomment if you want to include all pixels not just pixels of classvalue\n",
    "                    ).rename(ee.String('') #'class_count-'\n",
    "                                       .cat(ee.Number(classvalue).toInt().format()))\n",
    "\n",
    "## function to create image of count of each asClass\n",
    "def getcountbyclass(classvalue):\n",
    "    return ee.Image(toCount.updateMask(asClass.eq(classvalue)) #.And(toCount.gt(0))) # uncomment And statement if you want include only pixels that meet both criteria\n",
    "                    # .unmask(0) # uncomment if you want to include all pixels not just pixels of classvalue\n",
    "                    ).rename(ee.String('class_count-') #'class_count-'\n",
    "                                      .cat(ee.Number(classvalue).toInt().format()))\n",
    "\n",
    "## function to create image of count of each asClass filtered by toCount\n",
    "def getcountbyclassFilt(classvalue):\n",
    "    return ee.Image(toCount.updateMask(asClass.eq(classvalue).And(toCount.gt(0))) # uncomment And statement if you want include only pixels that meet both criteria\n",
    "                    # .unmask(0) # uncomment if you want to include all pixels not just pixels of classvalue\n",
    "                    ).rename(ee.String('class_countFilt-') #'class_count-'\n",
    "                                      .cat(ee.Number(classvalue).toInt().format()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ab7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create image with each WorldCover class mean as a band\n",
    "\n",
    "asClass = WorldCover\n",
    "toCount = LSTmean \n",
    "\n",
    "meanbyclass=ee.Image(getmeanbyclass(10)).addBands([\n",
    "  getmeanbyclass(20),  \n",
    "  getmeanbyclass(30),  \n",
    "  getmeanbyclass(40),  \n",
    "  getmeanbyclass(50),  \n",
    "  getmeanbyclass(60),\n",
    "  getmeanbyclass(70),  \n",
    "    getmeanbyclass(80), \n",
    "    getmeanbyclass(90), \n",
    "    getmeanbyclass(95), \n",
    "    getmeanbyclass(100), \n",
    "])\n",
    "\n",
    "## create image with each WorldCover class count as a band\n",
    "\n",
    "countbyclass=ee.Image(getcountbyclass(10)).addBands([\n",
    "  getcountbyclass(20),  \n",
    "  getcountbyclass(30),  \n",
    "  getcountbyclass(40),  \n",
    "  getcountbyclass(50),  \n",
    "  getcountbyclass(60),\n",
    "  getcountbyclass(70),  \n",
    "    getcountbyclass(80), \n",
    "    getcountbyclass(90), \n",
    "    getcountbyclass(95), \n",
    "    getcountbyclass(100), \n",
    "])\n",
    "\n",
    "## create image with each WorldCover class count above LST threshold as a band\n",
    "toCount = LSTmeanThres \n",
    "\n",
    "countbyclassFilt=ee.Image(getcountbyclassFilt(10)).addBands([\n",
    "  getcountbyclassFilt(20),  \n",
    "  getcountbyclassFilt(30),  \n",
    "  getcountbyclassFilt(40),  \n",
    "  getcountbyclassFilt(50),  \n",
    "  getcountbyclassFilt(60),\n",
    "  getcountbyclassFilt(70),  \n",
    "    getcountbyclassFilt(80), \n",
    "    getcountbyclassFilt(90), \n",
    "    getcountbyclassFilt(95), \n",
    "    getcountbyclassFilt(100), \n",
    "])\n",
    "\n",
    "#print('meanbyclass', meanbyclass.getInfo())\n",
    "#print('countbyclass', countbyclass.getInfo())\n",
    "#print('countbyclassFilt', countbyclassFilt.getInfo())\n",
    "\n",
    "#Map.addLayer(meanbyclass.select('50'),{},\"meanbyWCclass\")\n",
    "#Map.addLayer(countbyclassFilt.select('class_countFilt-10'),{},\"countbyFiltWCclass\")\n",
    "#Map.addLayer(countbyclass.select('class_count-10'),{},\"countbyWCclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc34d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create image with each ULU class mean as a band\n",
    "\n",
    "asClass = ULUmaskedESA\n",
    "toCount = LSTmean \n",
    "\n",
    "meanbyclassULU=ee.Image(getmeanbyclass(0)).addBands([\n",
    "  getmeanbyclass(1),  \n",
    "  getmeanbyclass(2),  \n",
    "  getmeanbyclass(3),  \n",
    "  getmeanbyclass(4),  \n",
    "  getmeanbyclass(5),\n",
    "  getmeanbyclass(6) \n",
    "])\n",
    "\n",
    "## create image with each ULU class count as a band\n",
    "\n",
    "countbyclassULU=ee.Image(getcountbyclass(0)).addBands([\n",
    "  getcountbyclass(1),  \n",
    "  getcountbyclass(2),  \n",
    "  getcountbyclass(3),  \n",
    "  getcountbyclass(4),  \n",
    "  getcountbyclass(5),\n",
    "  getcountbyclass(6)\n",
    "])\n",
    "\n",
    "## create image with each WorldCover class count above LST threshold as a band\n",
    "toCount = LSTmeanThres \n",
    "\n",
    "countbyclassFiltULU=ee.Image(getcountbyclassFilt(0)).addBands([\n",
    "  getcountbyclassFilt(1),  \n",
    "  getcountbyclassFilt(2),  \n",
    "  getcountbyclassFilt(3),  \n",
    "  getcountbyclassFilt(4),  \n",
    "  getcountbyclassFilt(5),\n",
    "  getcountbyclassFilt(6)\n",
    "])\n",
    "\n",
    "#Map.addLayer(meanbyclassULU.select('1'),{},\"meanbyULUclass\")\n",
    "#Map.addLayer(countbyclassFiltULU.select('class_countFilt-0'),{},\"countbyFiltULUclass\")\n",
    "#Map.addLayer(countbyclassULU.select('class_count-0'),{},\"countbyULUclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725de6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create FeatureCollection with mean of count for each class for each feature\n",
    "\n",
    "histo=meanbyclass.reduceRegions(\n",
    "  reducer= ee.Reducer.mean(), \n",
    "  collection= Districts, \n",
    "  scale= 10, \n",
    "  tileScale= 1\n",
    ")\n",
    "\n",
    "histo=countbyclass.reduceRegions(\n",
    "  reducer= ee.Reducer.count(), \n",
    "  collection= histo, \n",
    "  scale= 10, \n",
    "  tileScale= 1\n",
    ")\n",
    "\n",
    "histo=countbyclassFilt.reduceRegions(\n",
    "  reducer= ee.Reducer.count(), \n",
    "  collection= histo, \n",
    "  scale= 10, \n",
    "  tileScale= 1\n",
    ")\n",
    "\n",
    "histo=meanbyclassULU.reduceRegions(\n",
    "  reducer= ee.Reducer.mean(), \n",
    "  collection= histo, \n",
    "  scale= 10, \n",
    "  tileScale= 1\n",
    ")\n",
    "\n",
    "histo=countbyclassULU.reduceRegions(\n",
    "  reducer= ee.Reducer.count(), \n",
    "  collection= histo, \n",
    "  scale= 10, \n",
    "  tileScale= 1\n",
    ")\n",
    "\n",
    "histo=countbyclassFiltULU.reduceRegions(\n",
    "  reducer= ee.Reducer.count(), \n",
    "  collection= histo, \n",
    "  scale= 10, \n",
    "  tileScale= 1\n",
    ")\n",
    "\n",
    "#print('histo:', histo.limit(1,'class_count-10',False).getInfo())\n",
    "print('histo:', histo.first().toDictionary().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e017c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define function to normalize count as percent of all pixels in each feature and create new properties with the values\n",
    "\n",
    "def count_to_percent(feat):\n",
    "    feat=ee.Feature(feat)\n",
    "    hist=ee.Dictionary(feat.toDictionary(['10','20','30','40','50','60','70','80','90','95','100']))\n",
    "    hist=hist.set('10',hist.get('10',0))\n",
    "    hist=hist.set('20',hist.get('20',0))\n",
    "    hist=hist.set('30',hist.get('30',0))\n",
    "    hist=hist.set('40',hist.get('40',0))\n",
    "    hist=hist.set('50',hist.get('50',0))\n",
    "    hist=hist.set('60',hist.get('60',0))\n",
    "    hist=hist.set('70',hist.get('70',0))\n",
    "    hist=hist.set('80',hist.get('80',0))\n",
    "    hist=hist.set('90',hist.get('90',0))\n",
    "    hist=hist.set('95',hist.get('95',0))\n",
    "    hist=hist.set('100',hist.get('100',0))\n",
    "    \n",
    "    def pct_hist(k,v):\n",
    "        # convert whole number (0-100) to decimal percent (0-1)\n",
    "        return ee.Number(v)\n",
    "    \n",
    "    meansLULC = hist.map(pct_hist)\n",
    "    \n",
    "    histC=ee.Dictionary(feat.toDictionary(['class_count-10','class_count-20','class_count-30','class_count-40','class_count-50','class_count-60','class_count-70','class_count-80','class_count-90','class_count-95','class_count-100']))\n",
    "    histC=histC.set('10',histC.get('class_count-10',0))\n",
    "    histC=histC.set('20',histC.get('class_count-20',0))\n",
    "    histC=histC.set('30',histC.get('class_count-30',0))\n",
    "    histC=histC.set('40',histC.get('class_count-40',0))\n",
    "    histC=histC.set('50',histC.get('class_count-50',0))\n",
    "    histC=histC.set('60',histC.get('class_count-60',0))\n",
    "    histC=histC.set('70',histC.get('class_count-70',0))\n",
    "    histC=histC.set('80',histC.get('class_count-80',0))\n",
    "    histC=histC.set('90',histC.get('class_count-90',0))\n",
    "    histC=histC.set('95',histC.get('class_count-95',0))\n",
    "    histC=histC.set('100',histC.get('class_count-100',0))\n",
    "    \n",
    "    histCfilt=ee.Dictionary(feat.toDictionary(['class_countFilt-10','class_countFilt-20','class_countFilt-30','class_countFilt-40','class_countFilt-50','class_countFilt-60','class_countFilt-70','class_countFilt-80','class_countFilt-90','class_countFilt-95','class_countFilt-100']))\n",
    "    histCfilt=histCfilt.set('10',histCfilt.get('class_countFilt-10',0))\n",
    "    histCfilt=histCfilt.set('20',histCfilt.get('class_countFilt-20',0))\n",
    "    histCfilt=histCfilt.set('30',histCfilt.get('class_countFilt-30',0))\n",
    "    histCfilt=histCfilt.set('40',histCfilt.get('class_countFilt-40',0))\n",
    "    histCfilt=histCfilt.set('50',histCfilt.get('class_countFilt-50',0))\n",
    "    histCfilt=histCfilt.set('60',histCfilt.get('class_countFilt-60',0))\n",
    "    histCfilt=histCfilt.set('70',histCfilt.get('class_countFilt-70',0))\n",
    "    histCfilt=histCfilt.set('80',histCfilt.get('class_countFilt-80',0))\n",
    "    histCfilt=histCfilt.set('90',histCfilt.get('class_countFilt-90',0))\n",
    "    histCfilt=histCfilt.set('95',histCfilt.get('class_countFilt-95',0))\n",
    "    histCfilt=histCfilt.set('100',histCfilt.get('class_countFilt-100',0))\n",
    "    \n",
    "    def area_hist(k,v):\n",
    "        # convert 10m pixel count of class to KM2 of class\n",
    "        return ee.Number(v).multiply(ee.Number(100)).multiply(ee.Number(0.000001))\n",
    "    \n",
    "    classAreas = histC.map(area_hist)\n",
    "    classFiltAreas = histCfilt.map(area_hist)\n",
    "\n",
    "    \n",
    "    FeatArea = feat.area(0.001).multiply(0.000001)\n",
    "    cityID = Areaofinterest\n",
    "    geo_level = feat.getString(\"geo_level\")\n",
    "    geo_name = feat.getString(\"geo_name\").split(' ').join('_')\n",
    "    #geo_name = feat.getString(\"Sub_City\").cat(ee.String(\"-\")).cat(feat.getString(\"Woreda\"))\n",
    "    #geo_name = feat.getString(\"city_name_viz\").split(' ').join('_')\n",
    "    #geo_name = feat.getString(\"City Name\")\n",
    "    geo_id = ee.String(cityID+\"-\").cat(geo_name)\n",
    "    source = \"Landsat, ESA WorldCover, WRI ULU\"\n",
    "\n",
    "    totalPixels=hist.values()\n",
    "    \n",
    "    histULU=ee.Dictionary(feat.toDictionary(['0','1','2','3','4','5','6']))\n",
    "    histULU=histULU.set('0',histULU.get('0',0))\n",
    "    histULU=histULU.set('1',histULU.get('1',0))\n",
    "    histULU=histULU.set('2',histULU.get('2',0))\n",
    "    histULU=histULU.set('3',histULU.get('3',0))\n",
    "    histULU=histULU.set('4',histULU.get('4',0))\n",
    "    histULU=histULU.set('5',histULU.get('5',0))\n",
    "    histULU=histULU.set('6',histULU.get('6',0))\n",
    "    \n",
    "    meansULU = histULU.map(pct_hist)\n",
    "        \n",
    "    histULUc=ee.Dictionary(feat.toDictionary(['class_count-0','class_count-1','class_count-2','class_count-3','class_count-4','class_count-5','class_count-6']))\n",
    "    histULUc=histULUc.set('0',histULUc.get('class_count-0',0))\n",
    "    histULUc=histULUc.set('1',histULUc.get('class_count-1',0))\n",
    "    histULUc=histULUc.set('2',histULUc.get('class_count-2',0))\n",
    "    histULUc=histULUc.set('3',histULUc.get('class_count-3',0))\n",
    "    histULUc=histULUc.set('4',histULUc.get('class_count-4',0))\n",
    "    histULUc=histULUc.set('5',histULUc.get('class_count-5',0))\n",
    "    histULUc=histULUc.set('6',histULUc.get('class_count-6',0))\n",
    "    \n",
    "    histULUcFilt=ee.Dictionary(feat.toDictionary(['class_countFilt-0','class_countFilt-1','class_countFilt-2','class_countFilt-3','class_countFilt-4','class_countFilt-5','class_countFilt-6']))\n",
    "    histULUcFilt=histULUcFilt.set('0',histULUcFilt.get('class_countFilt-0',0))\n",
    "    histULUcFilt=histULUcFilt.set('1',histULUcFilt.get('class_countFilt-1',0))\n",
    "    histULUcFilt=histULUcFilt.set('2',histULUcFilt.get('class_countFilt-2',0))\n",
    "    histULUcFilt=histULUcFilt.set('3',histULUcFilt.get('class_countFilt-3',0))\n",
    "    histULUcFilt=histULUcFilt.set('4',histULUcFilt.get('class_countFilt-4',0))\n",
    "    histULUcFilt=histULUcFilt.set('5',histULUcFilt.get('class_countFilt-5',0))\n",
    "    histULUcFilt=histULUcFilt.set('6',histULUcFilt.get('class_countFilt-6',0))\n",
    "\n",
    "    classAreasULU = histULUc.map(area_hist)\n",
    "    classFiltAreasULU = histULUcFilt.map(area_hist)\n",
    "\n",
    "    return feat.set({\n",
    "        'LC10LST': meansLULC.getNumber('10'),\n",
    "        'LC20LST': meansLULC.getNumber('20'),\n",
    "        'LC30LST': meansLULC.getNumber('30'),\n",
    "        'LC40LST': meansLULC.getNumber('40'),\n",
    "        'LC50LST': meansLULC.getNumber('50'),\n",
    "        'LC60LST': meansLULC.getNumber('60'),\n",
    "        'LC70LST': meansLULC.getNumber('70'),\n",
    "        'LC80LST': meansLULC.getNumber('80'),\n",
    "        'LC90LST': meansLULC.getNumber('90'),\n",
    "        'LC95LST': meansLULC.getNumber('95'),\n",
    "        'LC100LST': meansLULC.getNumber('100'),\n",
    "        'TotalareaKM2': FeatArea,\n",
    "        'TotalPixels': totalPixels,\n",
    "        'geo_level': geo_level,\n",
    "        'geo_name': geo_name,\n",
    "        'geo_id': geo_id,\n",
    "        'date_start': date_start,\n",
    "        'date_end': date_end,\n",
    "        'source':source,\n",
    "        'LC10areaKM2': classAreas.getNumber('10'),\n",
    "        'LC20areaKM2': classAreas.getNumber('20'),\n",
    "        'LC30areaKM2': classAreas.getNumber('30'),\n",
    "        'LC40areaKM2': classAreas.getNumber('40'),\n",
    "        'LC50areaKM2': classAreas.getNumber('50'),\n",
    "        'LC60areaKM2': classAreas.getNumber('60'),\n",
    "        'LC70areaKM2': classAreas.getNumber('70'),\n",
    "        'LC80areaKM2': classAreas.getNumber('80'),\n",
    "        'LC90areaKM2': classAreas.getNumber('90'),\n",
    "        'LC95areaKM2': classAreas.getNumber('95'),\n",
    "        'LC100areaKM2': classAreas.getNumber('100'),\n",
    "        'LC10highLSTpct': classFiltAreas.getNumber('10').divide(classAreas.getNumber('10')),\n",
    "        'LC20highLSTpct': classFiltAreas.getNumber('20').divide(classAreas.getNumber('20')),\n",
    "        'LC30highLSTpct': classFiltAreas.getNumber('30').divide(classAreas.getNumber('30')),\n",
    "        'LC40highLSTpct': classFiltAreas.getNumber('40').divide(classAreas.getNumber('40')),\n",
    "        'LC50highLSTpct': classFiltAreas.getNumber('50').divide(classAreas.getNumber('50')),\n",
    "        'LC60highLSTpct': classFiltAreas.getNumber('60').divide(classAreas.getNumber('60')),\n",
    "        'LC70highLSTpct': classFiltAreas.getNumber('70').divide(classAreas.getNumber('70')),\n",
    "        'LC80highLSTpct': classFiltAreas.getNumber('80').divide(classAreas.getNumber('80')),\n",
    "        'LC90highLSTpct': classFiltAreas.getNumber('90').divide(classAreas.getNumber('90')),\n",
    "        'LC95highLSTpct': classFiltAreas.getNumber('95').divide(classAreas.getNumber('95')),\n",
    "        'LC100highLSTpct': classFiltAreas.getNumber('100').divide(classAreas.getNumber('100')),\n",
    "        'ULU0LST': meansULU.getNumber('0'),\n",
    "        'ULU1LST': meansULU.getNumber('1'),\n",
    "        'ULU2LST': meansULU.getNumber('2'),\n",
    "        'ULU3LST': meansULU.getNumber('3'),\n",
    "        'ULU4LST': meansULU.getNumber('4'),\n",
    "        'ULU5LST': meansULU.getNumber('5'),\n",
    "        'ULU6LST': meansULU.getNumber('6'),\n",
    "        'ULU0areaKM2': classAreasULU.getNumber('0'),\n",
    "        'ULU1areaKM2': classAreasULU.getNumber('1'),\n",
    "        'ULU2areaKM2': classAreasULU.getNumber('2'),\n",
    "        'ULU3areaKM2': classAreasULU.getNumber('3'),\n",
    "        'ULU4areaKM2': classAreasULU.getNumber('4'),\n",
    "        'ULU5areaKM2': classAreasULU.getNumber('5'),\n",
    "        'ULU6areaKM2': classAreasULU.getNumber('6'),\n",
    "        'ULU0highLSTpct': classFiltAreasULU.getNumber('0').divide(classAreasULU.getNumber('0')),\n",
    "        'ULU1highLSTpct': classFiltAreasULU.getNumber('1').divide(classAreasULU.getNumber('1')),\n",
    "        'ULU2highLSTpct': classFiltAreasULU.getNumber('2').divide(classAreasULU.getNumber('2')),\n",
    "        'ULU3highLSTpct': classFiltAreasULU.getNumber('3').divide(classAreasULU.getNumber('3')),\n",
    "        'ULU4highLSTpct': classFiltAreasULU.getNumber('4').divide(classAreasULU.getNumber('4')),\n",
    "        'ULU5highLSTpct': classFiltAreasULU.getNumber('5').divide(classAreasULU.getNumber('5')),\n",
    "        'ULU6highLSTpct': classFiltAreasULU.getNumber('6').divide(classAreasULU.getNumber('6')),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d82610",
   "metadata": {},
   "outputs": [],
   "source": [
    "## update FeatureCollection with percents\n",
    "\n",
    "lst_means=histo.map(count_to_percent)\n",
    "\n",
    "#print('LST stats by Land Cover class for Districts',lst_means.limit(1).getInfo());\n",
    "print('LST stats by Land Cover class for Districts',lst_means.first().toDictionary().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9317528",
   "metadata": {},
   "outputs": [],
   "source": [
    "## render on map percent tree cover by class from feature collection\n",
    "\n",
    "empty = ee.Image().byte()\n",
    "Tpctfills = empty.paint(**{'featureCollection': lst_means,'color': 'LC50highLSTpct'})\n",
    "\n",
    "fillspalette = ['green', 'red']\n",
    "cmap1 = ['blue', 'cyan', 'green', 'yellow', 'red']\n",
    "Map.addLayer(Tpctfills, {'palette': fillspalette,'min':0,'max':1}, '% of built areas with high mean land surface temperature', True, 0.65)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1ffaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select properties to keep, sort features and create data frame to display properties\n",
    "lst_meansSort = lst_means.select([\n",
    "    'TotalareaKM2',\n",
    "    'geo_level',\n",
    "    'geo_name',\n",
    "    'geo_id',\n",
    "    'date_start',\n",
    "    'date_end',\n",
    "    'source',\n",
    "    'LC10LST','LC20LST','LC30LST','LC40LST','LC50LST','LC60LST','LC70LST','LC80LST','LC90LST','LC95LST','LC100LST',\n",
    "    'ULU0LST','ULU1LST','ULU2LST','ULU3LST','ULU4LST','ULU5LST','ULU6LST',\n",
    "    'LC10highLSTpct','LC20highLSTpct','LC30highLSTpct','LC40highLSTpct','LC50highLSTpct','LC60highLSTpct','LC70highLSTpct','LC80highLSTpct','LC90highLSTpct','LC95highLSTpct','LC100highLSTpct',\n",
    "    'ULU0highLSTpct','ULU1highLSTpct','ULU2highLSTpct','ULU3highLSTpct','ULU4highLSTpct','ULU5highLSTpct','ULU6highLSTpct',\n",
    "]).sort('LC50highLSTpct', False) #\n",
    "#print('Tree cover sorted version',tree_pctsSort.limit(1).getInfo());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = geemap.ee_to_pandas(lst_meansSort)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b5a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display features in chart\n",
    "\n",
    "import geemap.chart as chart\n",
    "\n",
    "xProperty = 'geo_name' #,\"Woreda\"\n",
    "yProperties = ['LC50highLSTpct'] # ,'LC50areaKM2'\n",
    "\n",
    "options = {\n",
    "    'xlabel': \"District\",\n",
    "    'ylabel': \"Percent of built area with LST of \"+str(thesholdAdder)+\"C+ above built-up mean during heat wave\",\n",
    "    \"legend_location\": \"top-right\",\n",
    "    \"height\": \"500px\",\n",
    "}\n",
    "\n",
    "chart.feature_byFeature(lst_meansSort, xProperty, yProperties, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff215e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ae679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3048601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d4d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
