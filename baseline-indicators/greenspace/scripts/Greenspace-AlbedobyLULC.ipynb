{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68546f99-1220-49dc-9ae3-4b95426b5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installations to run in Planetary Computer environment \n",
    "# import sys\n",
    "# !{sys.executable} -m pip install pip earthengine-api\n",
    "# !{sys.executable} -m pip install pip geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfbd47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "#ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2456da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "import ipyleaflet\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc7554",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify areas of interest / districts and metadata\n",
    "## URL method accessed an UrbanShift city's boundaries and uses information from file name and geoBoundaries properties (\"geo_name\") to create properties for output file\n",
    "URL = 'https://cities-urbanshift.s3.eu-west-3.amazonaws.com/data/boundaries/v_0/boundary-CRI-San_Jose-ADM2.geojson'\n",
    "#'https://cities-urbanshift.s3.eu-west-3.amazonaws.com/data/boundaries/ADM1/boundary-MAR-Marrakech-ADM1.geojson'\n",
    "DistrictsGJ = requests.get(URL).json()\n",
    "Districts = geemap.geojson_to_ee(DistrictsGJ)\n",
    "\n",
    "#URL = 'https://cities-urbanshift.s3.eu-west-3.amazonaws.com/data/boundaries/urban_edge_t3.geojson'\n",
    "#DistrictsGDF = gpd.read_file(URL)\n",
    "#DistrictsGDF.sample(3)\n",
    "#Districts = geemap.gdf_to_ee(DistrictsGDF)\n",
    "\n",
    "#Districts = ee.FeatureCollection('users/emackres/Wards/Addis_Ababa_Woredas')\n",
    "#Districts = ee.FeatureCollection('projects/wri-datalab/AUE/urban_edge/urban_edge_t3').first()\n",
    "\n",
    "cityname = os.path.splitext(os.path.basename(URL))[0].split('-',2)[2].rsplit('-',1)[0]\n",
    "def Rename(feat):\n",
    "    return feat.set('geo_name',cityname)\n",
    "#Districts = Districts.union(1).map(Rename)\n",
    "\n",
    "DistrictsProjCRS = Districts.geometry().projection().crs()\n",
    "print(DistrictsProjCRS.getInfo())\n",
    "print(Districts.first().getString('geo_name').getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb7d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract area properties from standarized filename\n",
    "# https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ \n",
    "basename = os.path.splitext(os.path.basename(URL))[0]\n",
    "AOIname = basename.split('-',1)[1].rsplit('-',1)[0]\n",
    "\n",
    "Areaofinterest = AOIname ## 3-letter country abreviation - city name with underscore for spaces, e.g. \"ETH-Addis_Ababa\"\n",
    "print(Areaofinterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30483f62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## create map\n",
    "Map = geemap.Map(height=\"350px\")\n",
    "#Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69433526",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add basemap and center on area of interest\n",
    "Map.add_basemap('HYBRID')\n",
    "Map.centerObject(Districts, zoom=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add Land use land cover dataset\n",
    "WC = ee.ImageCollection(\"ESA/WorldCover/v100\")\n",
    "WorldCover = WC.first();\n",
    "\n",
    "## define projection for use later\n",
    "WCprojection = WC.first().projection();  \n",
    "print('WorldCover projection:', WCprojection.getInfo());\n",
    "\n",
    "Map.addLayer(WorldCover, {'bands': \"Map\"}, \"WorldCover 10m 2020 (ESA)\",1);\n",
    "\n",
    "Map.add_legend(builtin_legend='ESA_WorldCover',position='bottomleft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b055b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add intra-urban land use dataset\n",
    "\n",
    "ULU = ee.ImageCollection(\"projects/wri-datalab/urban_land_use/v1\")\n",
    "\n",
    "WRIulu = ULU.select('lulc').reduce(ee.Reducer.firstNonNull()).rename('lulc')\n",
    "WRIulu = WRIulu.mask(WRIulu.mask().gt(0))\n",
    "WRIroad = ULU.select('road_lulc').reduce(ee.Reducer.firstNonNull()).rename('lulc')\n",
    "WRIuluwRoad = WRIulu.add(WRIroad).where(WRIroad.eq(1),6).mask(WRIulu.mask().gt(0))\n",
    "\n",
    "ULUmaskedESA = WRIuluwRoad.updateMask(WorldCover.eq(50)) #.Or(WorldCover.eq(60)))\n",
    "\n",
    "ULUmaskedESA = ULUmaskedESA.reproject(\n",
    "      crs= WCprojection\n",
    "    )\n",
    "\n",
    "CLASSES_7=[\n",
    "  \"open_space\",\n",
    "  \"nonresidential\",\n",
    "  \"atomistic\",\n",
    "  \"informal_subdivision\",\n",
    "  \"formal_subdivision\",\n",
    "  \"housing_project\",\n",
    "  \"road\"]\n",
    "COLORS_7=[\n",
    "  '33A02C',\n",
    "  'E31A1C',\n",
    "  'FB9A99',\n",
    "  'FFFF99',\n",
    "  '1F78B4',\n",
    "  'A6CEE3',\n",
    "  '3f3f3f']  \n",
    "ULU7Params = {\"bands\": ['lulc'], 'min': 0, 'max': 6, \"opacity\": 1, \"palette\": COLORS_7}\n",
    "\n",
    "Map.addLayer(ULUmaskedESA,ULU7Params,\"Urban Land Use 2020 (WRI) masked to WorldCover built\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c000d24-9728-40bf-be74-1a36d7f85dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set geometries and date range of interest for land surface temperature (LST) calculation\n",
    "\n",
    "roi = Districts\n",
    "ROIcenter = roi.geometry().centroid(1)\n",
    "\n",
    "date_start = '2020-01-01'\n",
    "date_end = '2021-01-01'\n",
    "image_limit = 50 # max number of images to include, sorted from least to most cloudy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a05962-85ff-4dde-9309-c4aebafeaa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## CONFIG\n",
    "\n",
    "S2 = ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
    "S2C = ee.ImageCollection(\"COPERNICUS/S2_CLOUD_PROBABILITY\")\n",
    "\n",
    "MAX_CLOUD_PROB=30\n",
    "S2_ALBEDO_EQN='((B*Bw)+(G*Gw)+(R*Rw)+(NIR*NIRw)+(SWIR1*SWIR1w)+(SWIR2*SWIR2w))'\n",
    "S2_VIZ = {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3};\n",
    "\n",
    "\n",
    "## METHODS\n",
    "\n",
    "def mask_clouds_and_rescale(im):\n",
    "    clouds=ee.Image(im.get('cloud_mask')).select('probability')\n",
    "    return im.updateMask(clouds.lt(MAX_CLOUD_PROB)).divide(10000)\n",
    "\n",
    "def get_masked_s2_collection(roi,start,end):\n",
    "  criteria=(ee.Filter.And(\n",
    "            ee.Filter.date(start,end),\n",
    "            ee.Filter.bounds(roi)\n",
    "        ))\n",
    "  s2=S2.filter(criteria).limit(image_limit,'CLOUDY_PIXEL_PERCENTAGE')#.select('B2','B3','B4','B8','B11','B12')\n",
    "  s2c=S2C.filter(criteria).limit(image_limit,'CLOUDY_PIXEL_PERCENTAGE')\n",
    "  joined=(ee.Join.saveFirst('cloud_mask').apply(**{\n",
    "        'primary': ee.ImageCollection(s2),\n",
    "        'secondary': ee.ImageCollection(s2c),\n",
    "        'condition': ee.Filter.equals(**{'leftField':'system:index','rightField':'system:index'}) \n",
    "  }))\n",
    "  cloudless=ee.ImageCollection(joined).map(mask_clouds_and_rescale)\n",
    "  return cloudless\n",
    "\n",
    "# weights derived from \n",
    "# S. Bonafoni and A. Sekertekin, \"Albedo Retrieval From Sentinel-2 by New Narrow-to-Broadband Conversion Coefficients,\" in IEEE Geoscience and Remote Sensing Letters, vol. 17, no. 9, pp. 1618-1622, Sept. 2020, doi: 10.1109/LGRS.2020.2967085.\n",
    "def calc_s2_albedo(image):\n",
    "  config={\n",
    "    'Bw':0.2266,\n",
    "    'Gw':0.1236,\n",
    "    'Rw':0.1573,\n",
    "    'NIRw':0.3417,\n",
    "    'SWIR1w':0.1170,\n",
    "    'SWIR2w':0.0338,\n",
    "    'B':image.select('B2'),\n",
    "    'G':image.select('B3'),\n",
    "    'R':image.select('B4'),\n",
    "    'NIR':image.select('B8'),\n",
    "    'SWIR1':image.select('B11'),\n",
    "    'SWIR2':image.select('B12')\n",
    "  }\n",
    "  return image.expression(S2_ALBEDO_EQN,config).double().rename('albedo')\n",
    "\n",
    "\n",
    "\n",
    "## S2 MOSAIC AND ALBEDO\n",
    "\n",
    "dataset = get_masked_s2_collection(roi,date_start,date_end)\n",
    "s2_albedo = dataset.map(calc_s2_albedo)\n",
    "mosaic=dataset.mean()\n",
    "#albedoMean=s2_albedo.mean()\n",
    "albedoMean=s2_albedo.reduce(ee.Reducer.mean())\n",
    "\n",
    "#print(dataset.size().getInfo())\n",
    "#print(albedoMean.getInfo())\n",
    "#print(albedoMean.projection().nominalScale().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de62ca-5b47-4125-9b54-23558bdfd9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define \"low albedo\" threshold\n",
    "LowAlbedoMax = 0.20 # EnergyStar steep slope minimum initial value is 0.25. 3-year value is 0.15. https://www.energystar.gov/products/building_products/roof_products/key_product_criteria\n",
    "albedoMeanThres = albedoMean.updateMask(albedoMean.lt(LowAlbedoMax))\n",
    "\n",
    "#Add S2 albedo means to map\n",
    "\n",
    "Map.addLayer(mosaic, S2_VIZ, 'S2',False)\n",
    "Map.addLayer(albedoMean, {'min':0, 'max':1}, 'S2 albedo',False)\n",
    "Map.addLayer(albedoMeanThres,{'min':0, 'max':1}, 'S2 albedo, areas below '+str(LowAlbedoMax)+' albedo',True)\n",
    "\n",
    "Map.addLayer(roi,{}, \"Area of interest\",False,0.3)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2679421",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculations to determine Albedo by LULC class\n",
    "\n",
    "\n",
    "## function to create image of means of toCount for each asClass\n",
    "\n",
    "def getmeanbyclass(classvalue):\n",
    "    return ee.Image(toCount.updateMask(asClass.eq(classvalue)) #.And(toCount.gt(0))) # uncomment And statement if you want include only pixels that meet both criteria\n",
    "                    # .unmask(0) # uncomment if you want to include all pixels not just pixels of classvalue\n",
    "                    ).rename(ee.String('') #'class_count-'\n",
    "                                       .cat(ee.Number(classvalue).toInt().format()))\n",
    "\n",
    "## function to create image of count of each asClass\n",
    "def getcountbyclass(classvalue):\n",
    "    return ee.Image(toCount.updateMask(asClass.eq(classvalue)) #.And(toCount.gt(0))) # uncomment And statement if you want include only pixels that meet both criteria\n",
    "                    # .unmask(0) # uncomment if you want to include all pixels not just pixels of classvalue\n",
    "                    ).rename(ee.String('class_count-') #'class_count-'\n",
    "                                      .cat(ee.Number(classvalue).toInt().format()))\n",
    "\n",
    "## function to create image of count of each asClass filtered by toCount\n",
    "def getcountbyclassFilt(classvalue):\n",
    "    return ee.Image(toCount.updateMask(asClass.eq(classvalue).And(toCount.gte(0))) # uncomment And statement if you want include only pixels that meet both criteria\n",
    "                    # .unmask(0) # uncomment if you want to include all pixels not just pixels of classvalue\n",
    "                    ).rename(ee.String('class_countFilt-') #'class_count-'\n",
    "                                      .cat(ee.Number(classvalue).toInt().format()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ab7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create image with each WorldCover class mean as a band\n",
    "\n",
    "asClass = WorldCover\n",
    "toCount = albedoMean \n",
    "\n",
    "meanbyclass=ee.Image(getmeanbyclass(10)).addBands([\n",
    "  getmeanbyclass(20),  \n",
    "  getmeanbyclass(30),  \n",
    "  getmeanbyclass(40),  \n",
    "  getmeanbyclass(50),  \n",
    "  getmeanbyclass(60),\n",
    "  getmeanbyclass(70),  \n",
    "    getmeanbyclass(80), \n",
    "    getmeanbyclass(90), \n",
    "    getmeanbyclass(95), \n",
    "    getmeanbyclass(100), \n",
    "])\n",
    "\n",
    "## create image with each WorldCover class count as a band\n",
    "\n",
    "countbyclass=ee.Image(getcountbyclass(10)).addBands([\n",
    "  getcountbyclass(20),  \n",
    "  getcountbyclass(30),  \n",
    "  getcountbyclass(40),  \n",
    "  getcountbyclass(50),  \n",
    "  getcountbyclass(60),\n",
    "  getcountbyclass(70),  \n",
    "    getcountbyclass(80), \n",
    "    getcountbyclass(90), \n",
    "    getcountbyclass(95), \n",
    "    getcountbyclass(100), \n",
    "])\n",
    "\n",
    "## create image with each WorldCover class count above LST threshold as a band\n",
    "toCount = albedoMeanThres \n",
    "\n",
    "countbyclassFilt=ee.Image(getcountbyclassFilt(10)).addBands([\n",
    "  getcountbyclassFilt(20),  \n",
    "  getcountbyclassFilt(30),  \n",
    "  getcountbyclassFilt(40),  \n",
    "  getcountbyclassFilt(50),  \n",
    "  getcountbyclassFilt(60),\n",
    "  getcountbyclassFilt(70),  \n",
    "    getcountbyclassFilt(80), \n",
    "    getcountbyclassFilt(90), \n",
    "    getcountbyclassFilt(95), \n",
    "    getcountbyclassFilt(100), \n",
    "])\n",
    "\n",
    "#print('meanbyclass', meanbyclass.getInfo())\n",
    "#print('countbyclass', countbyclass.getInfo())\n",
    "#print('countbyclassFilt', countbyclassFilt.getInfo())\n",
    "\n",
    "#Map.addLayer(meanbyclass.select('50'),{},\"meanbyWCclass\")\n",
    "#Map.addLayer(countbyclassFilt.select('class_countFilt-10'),{},\"countbyFiltWCclass\")\n",
    "#Map.addLayer(countbyclass.select('class_count-10'),{},\"countbyWCclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc34d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create image with each ULU class mean as a band\n",
    "\n",
    "asClass = ULUmaskedESA\n",
    "toCount = albedoMean \n",
    "\n",
    "meanbyclassULU=ee.Image(getmeanbyclass(0)).addBands([\n",
    "  getmeanbyclass(1),  \n",
    "  getmeanbyclass(2),  \n",
    "  getmeanbyclass(3),  \n",
    "  getmeanbyclass(4),  \n",
    "  getmeanbyclass(5),\n",
    "  getmeanbyclass(6) \n",
    "])\n",
    "\n",
    "## create image with each ULU class count as a band\n",
    "\n",
    "countbyclassULU=ee.Image(getcountbyclass(0)).addBands([\n",
    "  getcountbyclass(1),  \n",
    "  getcountbyclass(2),  \n",
    "  getcountbyclass(3),  \n",
    "  getcountbyclass(4),  \n",
    "  getcountbyclass(5),\n",
    "  getcountbyclass(6)\n",
    "])\n",
    "\n",
    "## create image with each WorldCover class count above LST threshold as a band\n",
    "toCount = albedoMeanThres \n",
    "\n",
    "countbyclassFiltULU=ee.Image(getcountbyclassFilt(0)).addBands([\n",
    "  getcountbyclassFilt(1),  \n",
    "  getcountbyclassFilt(2),  \n",
    "  getcountbyclassFilt(3),  \n",
    "  getcountbyclassFilt(4),  \n",
    "  getcountbyclassFilt(5),\n",
    "  getcountbyclassFilt(6)\n",
    "])\n",
    "\n",
    "#Map.addLayer(meanbyclassULU.select('1'),{},\"meanbyULUclass\")\n",
    "#Map.addLayer(countbyclassFiltULU.select('class_countFilt-0'),{},\"countbyFiltULUclass\")\n",
    "#Map.addLayer(countbyclassULU.select('class_count-0'),{},\"countbyULUclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725de6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## create FeatureCollection with mean of count for each class for each feature\n",
    "\n",
    "histo=meanbyclass.reduceRegions(\n",
    "  reducer= ee.Reducer.mean(), \n",
    "  collection= Districts, \n",
    "  scale= 10, \n",
    "  tileScale= 4\n",
    ")\n",
    "\n",
    "histo=countbyclass.reduceRegions(\n",
    "  reducer= ee.Reducer.count(), \n",
    "  collection= histo, \n",
    "  scale= 10, \n",
    "  tileScale= 4\n",
    ")\n",
    "\n",
    "histo=countbyclassFilt.reduceRegions(\n",
    "  reducer= ee.Reducer.count(), \n",
    "  collection= histo, \n",
    "  scale= 10, \n",
    "  tileScale= 4\n",
    ")\n",
    "\n",
    "histo=meanbyclassULU.reduceRegions(\n",
    "  reducer= ee.Reducer.mean(), \n",
    "  collection= histo, \n",
    "  scale= 10, \n",
    "  tileScale= 4\n",
    ")\n",
    "\n",
    "histo=countbyclassULU.reduceRegions(\n",
    "  reducer= ee.Reducer.count(), \n",
    "  collection= histo, \n",
    "  scale= 10, \n",
    "  tileScale= 4\n",
    ")\n",
    "\n",
    "histo=countbyclassFiltULU.reduceRegions(\n",
    "  reducer= ee.Reducer.count(), \n",
    "  collection= histo, \n",
    "  scale= 10, \n",
    "  tileScale= 4\n",
    ")\n",
    "\n",
    "#print('histo:', histo.limit(1,'class_count-10',False).getInfo())\n",
    "#print('histo:', histo.first().toDictionary().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e017c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define function to normalize count as percent of all pixels in each feature and create new properties with the values\n",
    "\n",
    "def count_to_percent(feat):\n",
    "    feat=ee.Feature(feat)\n",
    "    hist=ee.Dictionary(feat.toDictionary(['10','20','30','40','50','60','70','80','90','95','100']))\n",
    "    hist=hist.set('10',hist.get('10',0))\n",
    "    hist=hist.set('20',hist.get('20',0))\n",
    "    hist=hist.set('30',hist.get('30',0))\n",
    "    hist=hist.set('40',hist.get('40',0))\n",
    "    hist=hist.set('50',hist.get('50',0))\n",
    "    hist=hist.set('60',hist.get('60',0))\n",
    "    hist=hist.set('70',hist.get('70',0))\n",
    "    hist=hist.set('80',hist.get('80',0))\n",
    "    hist=hist.set('90',hist.get('90',0))\n",
    "    hist=hist.set('95',hist.get('95',0))\n",
    "    hist=hist.set('100',hist.get('100',0))\n",
    "    \n",
    "    def pct_hist(k,v):\n",
    "        # convert whole number (0-100) to decimal percent (0-1)\n",
    "        return ee.Number(v)\n",
    "    \n",
    "    meansLULC = hist.map(pct_hist)\n",
    "    \n",
    "    histC=ee.Dictionary(feat.toDictionary(['class_count-10','class_count-20','class_count-30','class_count-40','class_count-50','class_count-60','class_count-70','class_count-80','class_count-90','class_count-95','class_count-100']))\n",
    "    histC=histC.set('10',histC.get('class_count-10',0))\n",
    "    histC=histC.set('20',histC.get('class_count-20',0))\n",
    "    histC=histC.set('30',histC.get('class_count-30',0))\n",
    "    histC=histC.set('40',histC.get('class_count-40',0))\n",
    "    histC=histC.set('50',histC.get('class_count-50',0))\n",
    "    histC=histC.set('60',histC.get('class_count-60',0))\n",
    "    histC=histC.set('70',histC.get('class_count-70',0))\n",
    "    histC=histC.set('80',histC.get('class_count-80',0))\n",
    "    histC=histC.set('90',histC.get('class_count-90',0))\n",
    "    histC=histC.set('95',histC.get('class_count-95',0))\n",
    "    histC=histC.set('100',histC.get('class_count-100',0))\n",
    "    \n",
    "    histCfilt=ee.Dictionary(feat.toDictionary(['class_countFilt-10','class_countFilt-20','class_countFilt-30','class_countFilt-40','class_countFilt-50','class_countFilt-60','class_countFilt-70','class_countFilt-80','class_countFilt-90','class_countFilt-95','class_countFilt-100']))\n",
    "    histCfilt=histCfilt.set('10',histCfilt.get('class_countFilt-10',0))\n",
    "    histCfilt=histCfilt.set('20',histCfilt.get('class_countFilt-20',0))\n",
    "    histCfilt=histCfilt.set('30',histCfilt.get('class_countFilt-30',0))\n",
    "    histCfilt=histCfilt.set('40',histCfilt.get('class_countFilt-40',0))\n",
    "    histCfilt=histCfilt.set('50',histCfilt.get('class_countFilt-50',0))\n",
    "    histCfilt=histCfilt.set('60',histCfilt.get('class_countFilt-60',0))\n",
    "    histCfilt=histCfilt.set('70',histCfilt.get('class_countFilt-70',0))\n",
    "    histCfilt=histCfilt.set('80',histCfilt.get('class_countFilt-80',0))\n",
    "    histCfilt=histCfilt.set('90',histCfilt.get('class_countFilt-90',0))\n",
    "    histCfilt=histCfilt.set('95',histCfilt.get('class_countFilt-95',0))\n",
    "    histCfilt=histCfilt.set('100',histCfilt.get('class_countFilt-100',0))\n",
    "    \n",
    "    def area_hist(k,v):\n",
    "        # convert 10m pixel count of class to KM2 of class\n",
    "        return ee.Number(v).multiply(ee.Number(100)).multiply(ee.Number(0.000001))\n",
    "    \n",
    "    classAreas = histC.map(area_hist)\n",
    "    classFiltAreas = histCfilt.map(area_hist)\n",
    "\n",
    "    \n",
    "    FeatArea = feat.area(0.001).multiply(0.000001)\n",
    "    cityID = Areaofinterest\n",
    "    geo_level = feat.getString(\"geo_level\")\n",
    "    geo_name = feat.getString(\"geo_name\").split(' ').join('_')\n",
    "    #geo_name = feat.getString(\"Sub_City\").cat(ee.String(\"-\")).cat(feat.getString(\"Woreda\"))\n",
    "    #geo_name = feat.getString(\"city_name_viz\").split(' ').join('_')\n",
    "    #geo_name = feat.getString(\"City Name\")\n",
    "    geo_id = ee.String(cityID+\"-\").cat(geo_name)\n",
    "    source = \"Sentinel-2, ESA WorldCover, WRI ULU\"\n",
    "\n",
    "    totalPixels=hist.values()\n",
    "    \n",
    "    histULU=ee.Dictionary(feat.toDictionary(['0','1','2','3','4','5','6']))\n",
    "    histULU=histULU.set('0',histULU.get('0',0))\n",
    "    histULU=histULU.set('1',histULU.get('1',0))\n",
    "    histULU=histULU.set('2',histULU.get('2',0))\n",
    "    histULU=histULU.set('3',histULU.get('3',0))\n",
    "    histULU=histULU.set('4',histULU.get('4',0))\n",
    "    histULU=histULU.set('5',histULU.get('5',0))\n",
    "    histULU=histULU.set('6',histULU.get('6',0))\n",
    "    \n",
    "    meansULU = histULU.map(pct_hist)\n",
    "        \n",
    "    histULUc=ee.Dictionary(feat.toDictionary(['class_count-0','class_count-1','class_count-2','class_count-3','class_count-4','class_count-5','class_count-6']))\n",
    "    histULUc=histULUc.set('0',histULUc.get('class_count-0',0))\n",
    "    histULUc=histULUc.set('1',histULUc.get('class_count-1',0))\n",
    "    histULUc=histULUc.set('2',histULUc.get('class_count-2',0))\n",
    "    histULUc=histULUc.set('3',histULUc.get('class_count-3',0))\n",
    "    histULUc=histULUc.set('4',histULUc.get('class_count-4',0))\n",
    "    histULUc=histULUc.set('5',histULUc.get('class_count-5',0))\n",
    "    histULUc=histULUc.set('6',histULUc.get('class_count-6',0))\n",
    "    \n",
    "    histULUcFilt=ee.Dictionary(feat.toDictionary(['class_countFilt-0','class_countFilt-1','class_countFilt-2','class_countFilt-3','class_countFilt-4','class_countFilt-5','class_countFilt-6']))\n",
    "    histULUcFilt=histULUcFilt.set('0',histULUcFilt.get('class_countFilt-0',0))\n",
    "    histULUcFilt=histULUcFilt.set('1',histULUcFilt.get('class_countFilt-1',0))\n",
    "    histULUcFilt=histULUcFilt.set('2',histULUcFilt.get('class_countFilt-2',0))\n",
    "    histULUcFilt=histULUcFilt.set('3',histULUcFilt.get('class_countFilt-3',0))\n",
    "    histULUcFilt=histULUcFilt.set('4',histULUcFilt.get('class_countFilt-4',0))\n",
    "    histULUcFilt=histULUcFilt.set('5',histULUcFilt.get('class_countFilt-5',0))\n",
    "    histULUcFilt=histULUcFilt.set('6',histULUcFilt.get('class_countFilt-6',0))\n",
    "\n",
    "    classAreasULU = histULUc.map(area_hist)\n",
    "    classFiltAreasULU = histULUcFilt.map(area_hist)\n",
    "\n",
    "    return feat.set({\n",
    "        'LC10albedo': meansLULC.getNumber('10'),\n",
    "        'LC20albedo': meansLULC.getNumber('20'),\n",
    "        'LC30albedo': meansLULC.getNumber('30'),\n",
    "        'LC40albedo': meansLULC.getNumber('40'),\n",
    "        'LC50albedo': meansLULC.getNumber('50'),\n",
    "        'LC60albedo': meansLULC.getNumber('60'),\n",
    "        'LC70albedo': meansLULC.getNumber('70'),\n",
    "        'LC80albedo': meansLULC.getNumber('80'),\n",
    "        'LC90albedo': meansLULC.getNumber('90'),\n",
    "        'LC95albedo': meansLULC.getNumber('95'),\n",
    "        'LC100albedo': meansLULC.getNumber('100'),\n",
    "        'TotalareaKM2': FeatArea,\n",
    "        'TotalPixels': totalPixels,\n",
    "        'geo_level': geo_level,\n",
    "        'geo_name': geo_name,\n",
    "        'geo_id': geo_id,\n",
    "        'date_start': date_start,\n",
    "        'date_end': date_end,\n",
    "        'source':source,\n",
    "        'LC10areaKM2': classAreas.getNumber('10'),\n",
    "        'LC20areaKM2': classAreas.getNumber('20'),\n",
    "        'LC30areaKM2': classAreas.getNumber('30'),\n",
    "        'LC40areaKM2': classAreas.getNumber('40'),\n",
    "        'LC50areaKM2': classAreas.getNumber('50'),\n",
    "        'LC60areaKM2': classAreas.getNumber('60'),\n",
    "        'LC70areaKM2': classAreas.getNumber('70'),\n",
    "        'LC80areaKM2': classAreas.getNumber('80'),\n",
    "        'LC90areaKM2': classAreas.getNumber('90'),\n",
    "        'LC95areaKM2': classAreas.getNumber('95'),\n",
    "        'LC100areaKM2': classAreas.getNumber('100'),\n",
    "        'LC10lowAlbedoPct': classFiltAreas.getNumber('10').divide(classAreas.getNumber('10')),\n",
    "        'LC20lowAlbedoPct': classFiltAreas.getNumber('20').divide(classAreas.getNumber('20')),\n",
    "        'LC30lowAlbedoPct': classFiltAreas.getNumber('30').divide(classAreas.getNumber('30')),\n",
    "        'LC40lowAlbedoPct': classFiltAreas.getNumber('40').divide(classAreas.getNumber('40')),\n",
    "        'LC50lowAlbedoPct': classFiltAreas.getNumber('50').divide(classAreas.getNumber('50')),\n",
    "        'LC60lowAlbedoPct': classFiltAreas.getNumber('60').divide(classAreas.getNumber('60')),\n",
    "        'LC70lowAlbedoPct': classFiltAreas.getNumber('70').divide(classAreas.getNumber('70')),\n",
    "        'LC80lowAlbedoPct': classFiltAreas.getNumber('80').divide(classAreas.getNumber('80')),\n",
    "        'LC90lowAlbedoPct': classFiltAreas.getNumber('90').divide(classAreas.getNumber('90')),\n",
    "        'LC95lowAlbedoPct': classFiltAreas.getNumber('95').divide(classAreas.getNumber('95')),\n",
    "        'LC100lowAlbedoPct': classFiltAreas.getNumber('100').divide(classAreas.getNumber('100')),\n",
    "        'ULU0albedo': meansULU.getNumber('0'),\n",
    "        'ULU1albedo': meansULU.getNumber('1'),\n",
    "        'ULU2albedo': meansULU.getNumber('2'),\n",
    "        'ULU3albedo': meansULU.getNumber('3'),\n",
    "        'ULU4albedo': meansULU.getNumber('4'),\n",
    "        'ULU5albedo': meansULU.getNumber('5'),\n",
    "        'ULU6albedo': meansULU.getNumber('6'),\n",
    "        'ULU0areaKM2': classAreasULU.getNumber('0'),\n",
    "        'ULU1areaKM2': classAreasULU.getNumber('1'),\n",
    "        'ULU2areaKM2': classAreasULU.getNumber('2'),\n",
    "        'ULU3areaKM2': classAreasULU.getNumber('3'),\n",
    "        'ULU4areaKM2': classAreasULU.getNumber('4'),\n",
    "        'ULU5areaKM2': classAreasULU.getNumber('5'),\n",
    "        'ULU6areaKM2': classAreasULU.getNumber('6'),\n",
    "        'ULU0lowAlbedoPct': classFiltAreasULU.getNumber('0').divide(classAreasULU.getNumber('0')),\n",
    "        'ULU1lowAlbedoPct': classFiltAreasULU.getNumber('1').divide(classAreasULU.getNumber('1')),\n",
    "        'ULU2lowAlbedoPct': classFiltAreasULU.getNumber('2').divide(classAreasULU.getNumber('2')),\n",
    "        'ULU3lowAlbedoPct': classFiltAreasULU.getNumber('3').divide(classAreasULU.getNumber('3')),\n",
    "        'ULU4lowAlbedoPct': classFiltAreasULU.getNumber('4').divide(classAreasULU.getNumber('4')),\n",
    "        'ULU5lowAlbedoPct': classFiltAreasULU.getNumber('5').divide(classAreasULU.getNumber('5')),\n",
    "        'ULU6lowAlbedoPct': classFiltAreasULU.getNumber('6').divide(classAreasULU.getNumber('6')),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d82610",
   "metadata": {},
   "outputs": [],
   "source": [
    "## update FeatureCollection with percents\n",
    "\n",
    "albedo_means=histo.map(count_to_percent)\n",
    "\n",
    "#print('LST stats by Land Cover class for Districts',albedo_means.limit(1).getInfo());\n",
    "#print('Albedo stats by Land Cover class for Districts',albedo_means.first().toDictionary().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9317528",
   "metadata": {},
   "outputs": [],
   "source": [
    "## render on map percent tree cover by class from feature collection\n",
    "\n",
    "empty = ee.Image().byte()\n",
    "Tpctfills = empty.paint(**{'featureCollection': albedo_means,'color': 'LC50lowAlbedoPct'})\n",
    "\n",
    "fillspalette = ['green', 'red']\n",
    "cmap1 = ['blue', 'cyan', 'green', 'yellow', 'red']\n",
    "#Map.addLayer(Tpctfills, {'palette': fillspalette,'min':0,'max':1}, '% of built areas with low albedo', True, 0.65)\n",
    "#Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1ffaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select properties to keep, sort features and create data frame to display properties\n",
    "albedo_meansSort = albedo_means.select([\n",
    "    'TotalareaKM2',\n",
    "    'geo_level',\n",
    "    'geo_name',\n",
    "    'geo_id',\n",
    "    'date_start',\n",
    "    'date_end',\n",
    "    'source',\n",
    "    'LC10albedo','LC20albedo','LC30albedo','LC40albedo','LC50albedo','LC60albedo','LC70albedo','LC80albedo','LC90albedo','LC95albedo','LC100albedo',\n",
    "    'ULU0albedo','ULU1albedo','ULU2albedo','ULU3albedo','ULU4albedo','ULU5albedo','ULU6albedo',\n",
    "    'LC10lowAlbedoPct','LC20lowAlbedoPct','LC30lowAlbedoPct','LC40lowAlbedoPct','LC50lowAlbedoPct','LC60lowAlbedoPct','LC70lowAlbedoPct','LC80lowAlbedoPct','LC90lowAlbedoPct','LC95lowAlbedoPct','LC100lowAlbedoPct',\n",
    "    'ULU0lowAlbedoPct','ULU1lowAlbedoPct','ULU2lowAlbedoPct','ULU3lowAlbedoPct','ULU4lowAlbedoPct','ULU5lowAlbedoPct','ULU6lowAlbedoPct',\n",
    "]).sort('LC50lowAlbedoPct', False) #\n",
    "#print('Albedo means filtered and sorted',albedo_meansSort.limit(1).getInfo());\n",
    "#print('Albedo means filtered and sorted:', albedo_meansSort.first().toDictionary().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = geemap.ee_to_pandas(albedo_meansSort)\n",
    "#df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ec185-8998-4ad5-80f7-8c215c2e1957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GJS = geemap.ee_to_geojson(albedo_meansSort)\n",
    "# from ipyleaflet import GeoJSON\n",
    "# json_layer_2 = GeoJSON(\n",
    "#     data=GJS,\n",
    "#     name='US States EE JSON',\n",
    "#     hover_style={'fillColor': 'red', 'fillOpacity': 0.5},\n",
    "# )\n",
    "# Map.add_layer(json_layer_2)\n",
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b5a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display features in chart\n",
    "\n",
    "import geemap.chart as chart\n",
    "\n",
    "xProperty = 'geo_name' \n",
    "yProperties = ['LC50lowAlbedoPct'] # ,'LC50areaKM2'\n",
    "\n",
    "options = {\n",
    "    'xlabel': \"District\",\n",
    "    'ylabel': \"Percent of built area with albedo less than \"+str(LowAlbedoMax)+\"\",\n",
    "    \"legend_location\": \"top-right\",\n",
    "    \"height\": \"500px\",\n",
    "}\n",
    "\n",
    "#chart.feature_byFeature(albedo_meansSort, xProperty, yProperties, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d4d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download FeatureCollection of OpenBuiltAreaPct as shapefile to Google Drive\n",
    "\n",
    "# Set configuration parameters for output vector\n",
    "task_config = {\n",
    "    #'folder': 'gee-data',  # output Google Drive folder\n",
    "    'fileFormat': 'GeoJSON',\n",
    "    #'selectors': col_names,  # a list of properties/attributes to be exported\n",
    "}\n",
    "#print('Exporting {}'.format(OpenBuiltAreaPct))\n",
    "task = ee.batch.Export.table.toDrive(albedo_meansSort, 'albedo_meansSort', **task_config)\n",
    "task.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
