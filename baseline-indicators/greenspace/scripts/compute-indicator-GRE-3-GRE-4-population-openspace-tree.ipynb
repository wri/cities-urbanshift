{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a66a1-a3b7-4aee-98ab-2b826a1b6e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install pip earthengine-api\n",
    "# !{sys.executable} -m pip install pip geemap[all]\n",
    "# !{sys.executable} -m pip install pip rasterstats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f259e-62a6-4b7e-b879-8628b18a8741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73901903-5245-4507-950b-3a78b2e820b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff69f1a8-e7fa-40ac-81db-f9a67f1e82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import boto3\n",
    "import geopandas as gpd\n",
    "import io\n",
    "from rasterstats import zonal_stats\n",
    "import fiona\n",
    "import rasterio.mask\n",
    "import geemap\n",
    "import glob\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de7d4d-ed34-493b-8573-ab00825ca668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ea530a-3c18-423a-a28a-de82cfa137ff",
   "metadata": {},
   "source": [
    "# Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330baf82-21ca-423c-803a-37782d5d7357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory\n",
    "out_dir = os.getcwd()\n",
    "bucket_name = 'cities-urbanshift' \n",
    "aws_s3_dir = \"https://\"+bucket_name+\".s3.eu-west-3.amazonaws.com/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa5ee9-8643-433d-9275-0fbc3ba0230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of c4f cities\n",
    "boundary_georef = pd.read_csv(aws_s3_dir + '/boundaries/v_0/boundary_georef.csv')\n",
    "boundary_georef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e1c571-5f1e-4a24-8dd7-9222ffe1097a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compute indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2155f1c4-4efe-4b67-916f-29090041d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_GRE_3_23 = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a7e21-e324-45ec-bd84-51e0a682eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,len(boundary_georef)):\n",
    "for i in range(5,6):\n",
    "    print(i)\n",
    "    geo_name = boundary_georef.loc[i, 'geo_name']\n",
    "    print(\"\\n geo_name: \"+geo_name)\n",
    "    \n",
    "    boundary_id_aoi = boundary_georef.loc[i, 'geo_name']+'-'+boundary_georef.loc[i, 'aoi_boundary_name']\n",
    "    boundary_id_unit = boundary_georef.loc[i, 'geo_name']+'-'+boundary_georef.loc[i, 'units_boundary_name']\n",
    "\n",
    "    # process aoi level ------\n",
    "    print(\"\\n boundary_id_aoi: \"+boundary_id_aoi)\n",
    "    # read boundaries\n",
    "    boundary_path = aws_s3_dir +'/boundaries/v_0/boundary-'+boundary_id_aoi+'.geojson'\n",
    "    boundary_geo = requests.get(boundary_path).json()\n",
    "    boundary_geo_ee = geemap.geojson_to_ee(boundary_geo)\n",
    "    \n",
    "    #read open space\n",
    "    openspace_path = aws_s3_dir + '/open_space/openstreetmap/v_0/'+boundary_id_aoi+'-OSM-open_space-2022.geojson'\n",
    "    openspace_geo = requests.get(openspace_path).json()\n",
    "    openspace_geo_ee = geemap.geojson_to_ee(openspace_geo)\n",
    "    \n",
    "    #load population\n",
    "    pop = ee.ImageCollection('WorldPop/GP/100m/pop')\n",
    "    pop = (pop.filter(ee.Filter.And(\n",
    "        ee.Filter.bounds(boundary_geo_ee),\n",
    "        ee.Filter.inList('year',[2020])))\n",
    "        .select('population'))\n",
    "    popImg = pop.mean().rename('population')\n",
    "\n",
    "    popProj = pop.first().projection()\n",
    "    popScale = popProj.nominalScale()\n",
    "\n",
    "    # define threshold distance (m) and buffer open space areas by that to get recreation catchment\n",
    "    DistanceThres = 400 # meters distance from population to be considered\n",
    "    def amenityBuffer(feat):\n",
    "      feat = ee.Feature(feat)\n",
    "      return feat.buffer(DistanceThres)\n",
    "    RecCatchment = openspace_geo_ee.map(amenityBuffer)\n",
    "    RecCatchmentUnion = RecCatchment.union()\n",
    "    \n",
    "    #mask population by recreation catchment\n",
    "    mask = ee.Image.constant(1).clip(RecCatchmentUnion.geometry()).mask()\n",
    "    popwOSaccess = popImg.updateMask(mask).rename('populationwOpenSpace')\n",
    "    \n",
    "    ## add tree cover dataset\n",
    "    TML = ee.ImageCollection('projects/wri-datalab/TML')\n",
    "    TreeCoverImg = TML.reduce(ee.Reducer.mean()).rename('b1')\n",
    "    TreeDataMask = TreeCoverImg.unmask(-99).neq(-99) \n",
    "    \n",
    "    \n",
    "    # calcs for % population with threshold level (e.g. 10%+) of tree cover within walking distance (e.g. 400m)\n",
    "    TreePctThreshold = 10 #whole numbers - 0-100, minimum percentage of tree cover threshold to consider \n",
    "    circleTheshm = ee.Kernel.circle(DistanceThres, 'meters', False)\n",
    "    TreeCoverinThreshm = TreeCoverImg.reduceNeighborhood(ee.Reducer.mean(), circleTheshm)\n",
    "    popwthresTC = popImg.updateMask(TreeCoverinThreshm.gte(TreePctThreshold)).rename('populationwTreeCover')\n",
    "    \n",
    "    # combine images \n",
    "    combImg = popImg.addBands([popwOSaccess,popwthresTC])\n",
    "    \n",
    "    # function to calculate indicators\n",
    "    def calcs(feat):\n",
    "        treecoveraccessEq = feat.getNumber('populationwTreeCover').divide(feat.getNumber('population'))\n",
    "        treecoveraccess = ee.Algorithms.If(feat.getNumber('TreeDataAvailable').eq(0),\"NA\",treecoveraccessEq)\n",
    "        openspaceaccess = feat.getNumber('populationwOpenSpace').divide(feat.getNumber('population'))\n",
    "        return feat.set({\n",
    "        'PopwOpenSpaceAccessPct': openspaceaccess,\n",
    "        'PopwTreeCoverAccessPct': treecoveraccess\n",
    "     }) \n",
    "\n",
    "    # use sum reducer to get total populations by features \n",
    "    PopbyDistrict=combImg.reduceRegions(reducer= ee.Reducer.sum(), collection=boundary_geo_ee, scale= popScale, tileScale= 4)\n",
    "    PopbyDistrict = TreeDataMask.reduceRegions(PopbyDistrict,ee.Reducer.anyNonZero().setOutputs(['TreeDataAvailable']),50)\n",
    "\n",
    "    # # apply function\n",
    "    PopbyDistrict = PopbyDistrict.map(calcs).select(['geo_id','PopwOpenSpaceAccessPct','PopwTreeCoverAccessPct'])\n",
    "    \n",
    "    # store in df and apend\n",
    "    df = geemap.ee_to_pandas(PopbyDistrict)#,['geo_id','PopwOpenSpaceAccessPct'])\n",
    "    df = df.rename(columns={\"PopwOpenSpaceAccessPct\": \"GRE_3_2_percentPopwOpenSpaceAccess\"}).rename(columns={\"PopwTreeCoverAccessPct\": \"GRE_3_3_percentPopwTreeCoverAccess\"})\n",
    "    cities_indicators_GRE_3_23 = cities_indicators_GRE_3_23.append(df)\n",
    "    \n",
    "    \n",
    "    # process unit of analysis level ------\n",
    "    print(\"\\n boundary_id_unit: \"+boundary_id_unit)\n",
    "    # read boundaries\n",
    "    boundary_path = aws_s3_dir +'/boundaries/v_0/boundary-'+boundary_id_unit+'.geojson'\n",
    "    boundary_geo = requests.get(boundary_path).json()\n",
    "    boundary_geo_ee = geemap.geojson_to_ee(boundary_geo)\n",
    "    \n",
    "    # use sum reducer to get total populations by features \n",
    "    PopbyDistrict=combImg.reduceRegions(reducer= ee.Reducer.sum(), collection=boundary_geo_ee, scale= popScale, tileScale= 4)\n",
    "    PopbyDistrict = TreeDataMask.reduceRegions(PopbyDistrict,ee.Reducer.anyNonZero().setOutputs(['TreeDataAvailable']),50)\n",
    "    \n",
    "    # apply function\n",
    "    PopbyDistrict = PopbyDistrict.map(calcs).select(['geo_id','PopwOpenSpaceAccessPct','PopwTreeCoverAccessPct'])\n",
    "    \n",
    "    # store in df and apend\n",
    "    df = geemap.ee_to_pandas(PopbyDistrict)\n",
    "    df = df.rename(columns={\"PopwOpenSpaceAccessPct\": \"GRE_3_2_percentPopwOpenSpaceAccess\"}).rename(columns={\"PopwTreeCoverAccessPct\": \"GRE_3_3_percentPopwTreeCoverAccess\"})\n",
    "    cities_indicators_GRE_3_23 = cities_indicators_GRE_3_23.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e653e42-eea8-4d5e-9031-47057258741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_GRE_3_23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ce6f62-6eac-4af0-b997-bd4ca4208fda",
   "metadata": {},
   "source": [
    "# Workaround for geographies with a lot of open space that won't load into memory - must be run one city at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33865a-ba54-49ef-abce-930739dd7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of c4f cities\n",
    "boundary_georef = pd.read_csv(aws_s3_dir +'/boundaries/v_0/boundary_georef.csv')\n",
    "boundary_georef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5410b-59b1-448c-9a37-907519c8504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete any existing GEE asset for openspace\n",
    "ee.data.deleteAsset('users/emackres/thisopenspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425b62c-1716-4bbe-82a0-ba2b02583c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate city - adjust range to include single city of interest\n",
    "for i in range(6,7): #len(boundary_georef)):\n",
    "    print(i)\n",
    "    geo_name = boundary_georef.loc[i, 'geo_name']\n",
    "    print(\"\\n geo_name: \"+geo_name)\n",
    "    \n",
    "    boundary_id_aoi = boundary_georef.loc[i, 'geo_name']+'-'+boundary_georef.loc[i, 'aoi_boundary_name']\n",
    "    boundary_id_unit = boundary_georef.loc[i, 'geo_name']+'-'+boundary_georef.loc[i, 'units_boundary_name']\n",
    "\n",
    "    #read open space\n",
    "    openspace_path = aws_s3_dir +'/open_space/openstreetmap/v_0/'+boundary_id_aoi+'-OSM-open_space-2022.geojson'\n",
    "    openspace_geo = requests.get(openspace_path).json()\n",
    "    openspace_geo_ee = geemap.geojson_to_ee(openspace_geo)\n",
    "\n",
    "    exportTask = ee.batch.Export.table.toAsset(\n",
    "        collection = openspace_geo_ee,\n",
    "        description = 'description',\n",
    "        assetId = 'users/emackres/thisopenspace'\n",
    "    )\n",
    "    exportTask.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6080c-6056-4e19-bf22-b82822d5c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportTask.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b472607e-bc67-4725-b92b-ecd006b659d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load saved asset - wait until task status says \"COMPLETED\"\n",
    "openspace_geo_ee = ee.FeatureCollection('users/emackres/thisopenspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b49bcda-0424-41ae-8914-787558cf765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6,7): #len(boundary_georef)):\n",
    "    print(i)\n",
    "    geo_name = boundary_georef.loc[i, 'geo_name']\n",
    "    print(\"\\n geo_name: \"+geo_name)\n",
    "    \n",
    "    boundary_id_aoi = boundary_georef.loc[i, 'geo_name']+'-'+boundary_georef.loc[i, 'aoi_boundary_name']\n",
    "    boundary_id_unit = boundary_georef.loc[i, 'geo_name']+'-'+boundary_georef.loc[i, 'units_boundary_name']\n",
    "\n",
    "    # process aoi level ------\n",
    "    print(\"\\n boundary_id_aoi: \"+boundary_id_aoi)\n",
    "    # read boundaries\n",
    "    boundary_path = aws_s3_dir +'/boundaries/v_0/boundary-'+boundary_id_aoi+'.geojson'\n",
    "    boundary_geo = requests.get(boundary_path).json()\n",
    "    boundary_geo_ee = geemap.geojson_to_ee(boundary_geo)\n",
    "    \n",
    "    # #read open space\n",
    "    # openspace_path = aws_s3_dir + '/open_space/openstreetmap/v_0/'+boundary_id_aoi+'-OSM-open_space-2022.geojson'\n",
    "    # openspace_geo = requests.get(openspace_path).json()\n",
    "    # openspace_geo_ee = geemap.geojson_to_ee(openspace_geo)\n",
    "    \n",
    "    #load population\n",
    "    pop = ee.ImageCollection('WorldPop/GP/100m/pop')\n",
    "    pop = (pop.filter(ee.Filter.And(\n",
    "        ee.Filter.bounds(boundary_geo_ee),\n",
    "        ee.Filter.inList('year',[2020])))\n",
    "        .select('population'))\n",
    "    popImg = pop.mean().rename('population')\n",
    "\n",
    "    popProj = pop.first().projection()\n",
    "    popScale = popProj.nominalScale()\n",
    "\n",
    "    # define threshold distance (m) and buffer open space areas by that to get recreation catchment\n",
    "    DistanceThres = 400 # meters distance from population to be considered\n",
    "    def amenityBuffer(feat):\n",
    "      feat = ee.Feature(feat)\n",
    "      return feat.buffer(DistanceThres)\n",
    "    RecCatchment = openspace_geo_ee.map(amenityBuffer)\n",
    "    RecCatchmentUnion = RecCatchment.union()\n",
    "    \n",
    "    #mask population by recreation catchment\n",
    "    mask = ee.Image.constant(1).clip(RecCatchmentUnion.geometry()).mask()\n",
    "    popwOSaccess = popImg.updateMask(mask).rename('populationwOpenSpace')\n",
    "    \n",
    "    ## add tree cover dataset\n",
    "    TML = ee.ImageCollection('projects/wri-datalab/TML')\n",
    "    TreeCoverImg = TML.reduce(ee.Reducer.mean()).rename('b1')\n",
    "    TreeDataMask = TreeCoverImg.unmask(-99).neq(-99) \n",
    "    \n",
    "    \n",
    "    # calcs for % population with threshold level (e.g. 10%+) of tree cover within walking distance (e.g. 400m)\n",
    "    TreePctThreshold = 10 #whole numbers - 0-100, minimum percentage of tree cover threshold to consider \n",
    "    circleTheshm = ee.Kernel.circle(DistanceThres, 'meters', False)\n",
    "    TreeCoverinThreshm = TreeCoverImg.reduceNeighborhood(ee.Reducer.mean(), circleTheshm)\n",
    "    popwthresTC = popImg.updateMask(TreeCoverinThreshm.gte(TreePctThreshold)).rename('populationwTreeCover')\n",
    "    \n",
    "    # combine images \n",
    "    combImg = popImg.addBands([popwOSaccess,popwthresTC])\n",
    "    \n",
    "    # function to calculate indicators\n",
    "    def calcs(feat):\n",
    "        treecoveraccessEq = feat.getNumber('populationwTreeCover').divide(feat.getNumber('population'))\n",
    "        treecoveraccess = ee.Algorithms.If(feat.getNumber('TreeDataAvailable').eq(0),\"NA\",treecoveraccessEq)\n",
    "        openspaceaccess = feat.getNumber('populationwOpenSpace').divide(feat.getNumber('population'))\n",
    "        return feat.set({\n",
    "        'PopwOpenSpaceAccessPct': openspaceaccess,\n",
    "        'PopwTreeCoverAccessPct': treecoveraccess\n",
    "     }) \n",
    "\n",
    "    # use sum reducer to get total populations by features \n",
    "    PopbyDistrict=combImg.reduceRegions(reducer= ee.Reducer.sum(), collection=boundary_geo_ee, scale= popScale, tileScale= 4)\n",
    "    PopbyDistrict = TreeDataMask.reduceRegions(PopbyDistrict,ee.Reducer.anyNonZero().setOutputs(['TreeDataAvailable']),50)\n",
    "\n",
    "    # # apply function\n",
    "    PopbyDistrict = PopbyDistrict.map(calcs).select(['geo_id','PopwOpenSpaceAccessPct','PopwTreeCoverAccessPct'])\n",
    "    \n",
    "    # store in df and apend\n",
    "    df = geemap.ee_to_pandas(PopbyDistrict)#,['geo_id','PopwOpenSpaceAccessPct'])\n",
    "    df = df.rename(columns={\"PopwOpenSpaceAccessPct\": \"GRE_3_2_percentPopwOpenSpaceAccess\"}).rename(columns={\"PopwTreeCoverAccessPct\": \"GRE_3_3_percentPopwTreeCoverAccess\"})\n",
    "    cities_indicators_GRE_3_23 = cities_indicators_GRE_3_23.append(df)\n",
    "    \n",
    "    \n",
    "    # process unit of analysis level ------\n",
    "    print(\"\\n boundary_id_unit: \"+boundary_id_unit)\n",
    "    # read boundaries\n",
    "    boundary_path = aws_s3_dir +'/boundaries/v_0/boundary-'+boundary_id_unit+'.geojson'\n",
    "    boundary_geo = requests.get(boundary_path).json()\n",
    "    boundary_geo_ee = geemap.geojson_to_ee(boundary_geo)\n",
    "    \n",
    "    # use sum reducer to get total populations by features \n",
    "    PopbyDistrict=combImg.reduceRegions(reducer= ee.Reducer.sum(), collection=boundary_geo_ee, scale= popScale, tileScale= 4)\n",
    "    PopbyDistrict = TreeDataMask.reduceRegions(PopbyDistrict,ee.Reducer.anyNonZero().setOutputs(['TreeDataAvailable']),50)\n",
    "    \n",
    "    # apply function\n",
    "    PopbyDistrict = PopbyDistrict.map(calcs).select(['geo_id','PopwOpenSpaceAccessPct','PopwTreeCoverAccessPct'])\n",
    "    \n",
    "    # store in df and apend\n",
    "    df = geemap.ee_to_pandas(PopbyDistrict)\n",
    "    df = df.rename(columns={\"PopwOpenSpaceAccessPct\": \"GRE_3_2_percentPopwOpenSpaceAccess\"}).rename(columns={\"PopwTreeCoverAccessPct\": \"GRE_3_3_percentPopwTreeCoverAccess\"})\n",
    "    cities_indicators_GRE_3_23 = cities_indicators_GRE_3_23.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e36d60-52d1-4a98-bbed-6271e2a20c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_GRE_3_23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5abd9b-097c-4676-a500-ecd45ad77374",
   "metadata": {},
   "source": [
    "# Merge with indicator table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731fba45-59b3-44fe-94a9-3520763dffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read indicator table\n",
    "cities_indicators = pd.read_csv('https://'+bucket_name+'.s3.eu-west-3.amazonaws.com/indicators/cities_indicators_ericV1.csv')\n",
    "cities_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978df631-317b-4c42-8c8a-d8ee108e1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_indicators(indicator_table, new_indicator_table, indicator_name):\n",
    "    if indicator_name in indicator_table.columns:\n",
    "        print(\"replace with new calculations\")\n",
    "        indicator_table.drop(indicator_name, inplace=True, axis=1)\n",
    "        new_indicator_table = new_indicator_table.drop_duplicates()\n",
    "        cities_indicators_df = indicator_table.merge(new_indicator_table[[\"geo_id\",indicator_name]], \n",
    "                                                     on='geo_id', \n",
    "                                                     how='left',\n",
    "                                                     validate='one_to_many')\n",
    "    else:\n",
    "        print(\"add new indicators\")\n",
    "        new_indicator_table = new_indicator_table.drop_duplicates()\n",
    "        cities_indicators_df = indicator_table.merge(new_indicator_table[[\"geo_id\",indicator_name]], \n",
    "                                                     on='geo_id', \n",
    "                                                     how='left',\n",
    "                                                     validate='one_to_many')\n",
    "    return(cities_indicators_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db9db7b-b300-4c06-aa58-3030b6f05d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_GRE_3_2 = cities_indicators_GRE_3_23[[\"geo_id\",\"GRE_3_2_percentPopwOpenSpaceAccess\"]]\n",
    "cities_indicators_GRE_3_3 = cities_indicators_GRE_3_23[[\"geo_id\",\"GRE_3_3_percentPopwTreeCoverAccess\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa73a3a-ea72-42ab-81ed-589b95ef33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_merged = merge_indicators(indicator_table = cities_indicators,\n",
    "                                            new_indicator_table = cities_indicators_GRE_3_2,\n",
    "                                            indicator_name = \"GRE_3_2_percentPopwOpenSpaceAccess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f07645-92df-4702-a81e-a50b7f7dfb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_merged = merge_indicators(indicator_table = cities_indicators_merged,\n",
    "                                            new_indicator_table = cities_indicators_GRE_3_3,\n",
    "                                            indicator_name = \"GRE_3_3_percentPopwTreeCoverAccess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c10c1e2-9aa9-4d43-a110-8550e4f36e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba258d2-9e13-4fcc-bf22-4aeb3f359405",
   "metadata": {},
   "source": [
    "# Upload in aws s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c059a57-b6a6-4354-b24b-f45102ec8399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to s3\n",
    "aws_credentials = pd.read_csv('/home/jovyan/PlanetaryComputerExamples/aws_credentials.csv')\n",
    "# aws_credentials = pd.read_csv('C:\\\\Users\\\\Saif.Shabou\\\\OneDrive - World Resources Institute\\\\Documents\\\\aws\\\\credentials.csv')\n",
    "aws_key = aws_credentials.iloc[0]['Access key ID']\n",
    "aws_secret = aws_credentials.iloc[0]['Secret access key']\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    aws_access_key_id=aws_key,\n",
    "    aws_secret_access_key=aws_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2235f8-fb77-40f6-91d8-908dca3fd164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to aws\n",
    "key_data = 'indicators/cities_indicators_ericV1.csv'\n",
    "\n",
    "cities_indicators_merged.to_csv(\n",
    "    f\"s3://{bucket_name}/{key_data}\",\n",
    "    index=False,\n",
    "    storage_options={\n",
    "        \"key\": aws_key,\n",
    "        \"secret\": aws_secret\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ed391-015d-4778-acc5-37c0c7a04703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it public\n",
    "object_acl = s3.ObjectAcl(bucket_name,key_data)\n",
    "response = object_acl.put(ACL='public-read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b91a451-afd4-4cc6-a685-8c4a5cbdd94b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
